{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GundetiManoj99/GAN/blob/main/GANs_for_image_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs('./results', exist_ok=True)"
      ],
      "metadata": {
        "id": "e4W9nd0x-gqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "\n",
        "batchSize = 64\n",
        "imageSize = 64\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize(imageSize), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), ])\n",
        "\n",
        "dataset = dset.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batchSize,\n",
        "    shuffle=True, num_workers=2)\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "class G(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(G,self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d(100,512,4,1,0,bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(512,256,4,2,1,bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(256,128,4,2,1,bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(128,64,4,2,1,bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(64,3,4,2,1,bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self,input):\n",
        "        output = self.main(input)\n",
        "        return output\n",
        "\n",
        "netG = G()\n",
        "netG.apply(weights_init)\n",
        "\n",
        "class D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(D,self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(3,64,4,2,1,bias=False),\n",
        "            nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "            nn.Conv2d(64,128,4,2,1,bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "            nn.Conv2d(128,256,4,2,1,bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "            nn.Conv2d(256,512,4,2,1,bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2,inplace=True),\n",
        "\n",
        "            nn.Conv2d(512,1,4,1,0,bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self,input):\n",
        "        output = self.main(input)\n",
        "        return output.view(-1)\n",
        "\n",
        "netD = D()\n",
        "netD.apply(weights_init)\n",
        "\n",
        "#training the DCGANs\n",
        "criterion = nn.BCELoss()\n",
        "optimizerD=optim.Adam(netD.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
        "optimizerG=optim.Adam(netG.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
        "\n",
        "for epoch in range(25):\n",
        "    for i,data in enumerate(dataloader,0):\n",
        "        netD.zero_grad()\n",
        "\n",
        "        real,_ = data\n",
        "        input = Variable(real)\n",
        "        target = Variable(torch.ones(input.size()[0]))\n",
        "\n",
        "        output = netD(input)\n",
        "        errD_real = criterion(output,target)\n",
        "\n",
        "        noise= torch.randn(input.size()[0],100,1,1)\n",
        "        fake = netG(noise)\n",
        "        target = Variable(torch.zeros(input.size()[0]))\n",
        "        output=netD(fake.detach())\n",
        "        errD_fake = criterion(output,target)\n",
        "\n",
        "        errD = errD_real + errD_fake\n",
        "        errD.backward()\n",
        "        optimizerD.step()\n",
        "\n",
        "        netG.zero_grad()\n",
        "        target = Variable(torch.ones(input.size()[0]))\n",
        "        output = netD(fake)\n",
        "        errG = criterion(output,target)\n",
        "        errG.backward()\n",
        "        optimizerG.step()\n",
        "\n",
        "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f'\n",
        "      % (epoch, 25, i, len(dataloader), errD.item(), errG.item()))\n",
        "\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            vutils.save_image(real, '%s/real_samples.png' % \"./results\", normalize=True)\n",
        "            fake = netG(noise)\n",
        "            vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' % (\"./results\", epoch), normalize=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sIjNy-29B7q",
        "outputId": "e3000705-5533-49da-98a3-6daec7a6b8f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "[0/25][0/782] Loss_D: 1.9561 Loss_G: 3.5374\n",
            "[0/25][1/782] Loss_D: 1.7260 Loss_G: 5.6722\n",
            "[0/25][2/782] Loss_D: 0.7783 Loss_G: 6.1428\n",
            "[0/25][3/782] Loss_D: 0.8105 Loss_G: 5.0774\n",
            "[0/25][4/782] Loss_D: 0.9128 Loss_G: 6.3546\n",
            "[0/25][5/782] Loss_D: 0.8207 Loss_G: 6.3343\n",
            "[0/25][6/782] Loss_D: 1.0429 Loss_G: 7.3977\n",
            "[0/25][7/782] Loss_D: 0.8047 Loss_G: 7.1952\n",
            "[0/25][8/782] Loss_D: 0.7260 Loss_G: 8.2272\n",
            "[0/25][9/782] Loss_D: 0.8734 Loss_G: 7.1575\n",
            "[0/25][10/782] Loss_D: 0.9650 Loss_G: 9.6688\n",
            "[0/25][11/782] Loss_D: 0.5394 Loss_G: 7.4198\n",
            "[0/25][12/782] Loss_D: 0.9489 Loss_G: 10.4453\n",
            "[0/25][13/782] Loss_D: 0.3765 Loss_G: 8.1937\n",
            "[0/25][14/782] Loss_D: 0.7240 Loss_G: 10.1110\n",
            "[0/25][15/782] Loss_D: 0.5230 Loss_G: 8.3624\n",
            "[0/25][16/782] Loss_D: 0.9508 Loss_G: 12.8917\n",
            "[0/25][17/782] Loss_D: 0.2990 Loss_G: 9.9956\n",
            "[0/25][18/782] Loss_D: 0.5405 Loss_G: 10.8091\n",
            "[0/25][19/782] Loss_D: 0.3119 Loss_G: 9.2934\n",
            "[0/25][20/782] Loss_D: 0.5496 Loss_G: 13.4103\n",
            "[0/25][21/782] Loss_D: 0.2580 Loss_G: 10.1326\n",
            "[0/25][22/782] Loss_D: 0.5519 Loss_G: 14.6106\n",
            "[0/25][23/782] Loss_D: 0.1822 Loss_G: 11.6241\n",
            "[0/25][24/782] Loss_D: 0.5255 Loss_G: 9.9892\n",
            "[0/25][25/782] Loss_D: 0.8605 Loss_G: 18.9188\n",
            "[0/25][26/782] Loss_D: 0.1965 Loss_G: 18.2547\n",
            "[0/25][27/782] Loss_D: 0.3663 Loss_G: 11.2844\n",
            "[0/25][28/782] Loss_D: 0.5993 Loss_G: 16.1521\n",
            "[0/25][29/782] Loss_D: 0.0965 Loss_G: 14.1621\n",
            "[0/25][30/782] Loss_D: 0.2834 Loss_G: 7.3911\n",
            "[0/25][31/782] Loss_D: 2.8052 Loss_G: 23.0540\n",
            "[0/25][32/782] Loss_D: 0.3820 Loss_G: 25.5525\n",
            "[0/25][33/782] Loss_D: 0.4372 Loss_G: 22.2859\n",
            "[0/25][34/782] Loss_D: 0.0702 Loss_G: 15.7657\n",
            "[0/25][35/782] Loss_D: 0.0175 Loss_G: 6.3625\n",
            "[0/25][36/782] Loss_D: 2.5627 Loss_G: 21.4256\n",
            "[0/25][37/782] Loss_D: 0.2217 Loss_G: 24.3639\n",
            "[0/25][38/782] Loss_D: 0.2066 Loss_G: 22.6252\n",
            "[0/25][39/782] Loss_D: 0.2991 Loss_G: 16.5144\n",
            "[0/25][40/782] Loss_D: 0.0897 Loss_G: 7.4321\n",
            "[0/25][41/782] Loss_D: 2.8792 Loss_G: 23.4231\n",
            "[0/25][42/782] Loss_D: 0.1081 Loss_G: 27.4178\n",
            "[0/25][43/782] Loss_D: 0.2336 Loss_G: 26.1039\n",
            "[0/25][44/782] Loss_D: 0.1348 Loss_G: 21.1688\n",
            "[0/25][45/782] Loss_D: 0.1221 Loss_G: 12.8067\n",
            "[0/25][46/782] Loss_D: 0.1211 Loss_G: 6.4093\n",
            "[0/25][47/782] Loss_D: 2.7706 Loss_G: 26.1520\n",
            "[0/25][48/782] Loss_D: 0.3130 Loss_G: 30.1820\n",
            "[0/25][49/782] Loss_D: 0.4250 Loss_G: 30.7283\n",
            "[0/25][50/782] Loss_D: 0.0844 Loss_G: 30.1977\n",
            "[0/25][51/782] Loss_D: 0.1311 Loss_G: 28.8705\n",
            "[0/25][52/782] Loss_D: 0.0808 Loss_G: 25.6125\n",
            "[0/25][53/782] Loss_D: 0.0105 Loss_G: 18.0564\n",
            "[0/25][54/782] Loss_D: 0.0099 Loss_G: 8.4170\n",
            "[0/25][55/782] Loss_D: 1.4131 Loss_G: 22.6242\n",
            "[0/25][56/782] Loss_D: 0.0602 Loss_G: 25.8898\n",
            "[0/25][57/782] Loss_D: 0.1203 Loss_G: 23.8429\n",
            "[0/25][58/782] Loss_D: 0.2316 Loss_G: 17.0594\n",
            "[0/25][59/782] Loss_D: 0.1039 Loss_G: 7.0510\n",
            "[0/25][60/782] Loss_D: 2.8576 Loss_G: 26.8493\n",
            "[0/25][61/782] Loss_D: 2.2964 Loss_G: 28.9160\n",
            "[0/25][62/782] Loss_D: 0.4968 Loss_G: 27.9144\n",
            "[0/25][63/782] Loss_D: 0.0432 Loss_G: 24.8099\n",
            "[0/25][64/782] Loss_D: 0.0284 Loss_G: 18.7269\n",
            "[0/25][65/782] Loss_D: 0.0289 Loss_G: 10.0954\n",
            "[0/25][66/782] Loss_D: 0.2976 Loss_G: 11.2951\n",
            "[0/25][67/782] Loss_D: 0.0352 Loss_G: 9.9740\n",
            "[0/25][68/782] Loss_D: 0.0332 Loss_G: 7.3174\n",
            "[0/25][69/782] Loss_D: 0.1971 Loss_G: 9.3607\n",
            "[0/25][70/782] Loss_D: 0.2060 Loss_G: 7.3118\n",
            "[0/25][71/782] Loss_D: 0.1971 Loss_G: 9.9544\n",
            "[0/25][72/782] Loss_D: 0.2683 Loss_G: 7.5454\n",
            "[0/25][73/782] Loss_D: 0.3212 Loss_G: 12.8098\n",
            "[0/25][74/782] Loss_D: 0.1558 Loss_G: 11.5275\n",
            "[0/25][75/782] Loss_D: 0.0688 Loss_G: 7.0566\n",
            "[0/25][76/782] Loss_D: 0.6875 Loss_G: 20.5608\n",
            "[0/25][77/782] Loss_D: 0.6399 Loss_G: 21.6682\n",
            "[0/25][78/782] Loss_D: 0.3712 Loss_G: 18.5184\n",
            "[0/25][79/782] Loss_D: 0.0746 Loss_G: 13.5548\n",
            "[0/25][80/782] Loss_D: 0.0159 Loss_G: 7.0623\n",
            "[0/25][81/782] Loss_D: 0.6548 Loss_G: 18.0647\n",
            "[0/25][82/782] Loss_D: 0.1616 Loss_G: 19.3099\n",
            "[0/25][83/782] Loss_D: 0.1429 Loss_G: 15.1880\n",
            "[0/25][84/782] Loss_D: 0.1193 Loss_G: 8.4294\n",
            "[0/25][85/782] Loss_D: 0.2429 Loss_G: 10.5123\n",
            "[0/25][86/782] Loss_D: 0.0395 Loss_G: 9.3022\n",
            "[0/25][87/782] Loss_D: 0.2460 Loss_G: 6.4939\n",
            "[0/25][88/782] Loss_D: 0.5968 Loss_G: 16.4781\n",
            "[0/25][89/782] Loss_D: 0.1719 Loss_G: 18.1847\n",
            "[0/25][90/782] Loss_D: 0.1762 Loss_G: 15.2444\n",
            "[0/25][91/782] Loss_D: 0.0885 Loss_G: 9.5402\n",
            "[0/25][92/782] Loss_D: 0.1122 Loss_G: 5.3452\n",
            "[0/25][93/782] Loss_D: 1.5940 Loss_G: 26.8092\n",
            "[0/25][94/782] Loss_D: 0.6980 Loss_G: 30.9338\n",
            "[0/25][95/782] Loss_D: 0.5119 Loss_G: 31.0805\n",
            "[0/25][96/782] Loss_D: 0.2567 Loss_G: 29.7448\n",
            "[0/25][97/782] Loss_D: 0.0744 Loss_G: 27.9723\n",
            "[0/25][98/782] Loss_D: 0.0663 Loss_G: 24.8726\n",
            "[0/25][99/782] Loss_D: 0.0153 Loss_G: 19.2641\n",
            "[0/25][100/782] Loss_D: 0.0107 Loss_G: 11.2142\n",
            "[0/25][101/782] Loss_D: 0.2712 Loss_G: 12.4808\n",
            "[0/25][102/782] Loss_D: 0.0372 Loss_G: 10.6098\n",
            "[0/25][103/782] Loss_D: 0.0341 Loss_G: 7.2603\n",
            "[0/25][104/782] Loss_D: 0.1207 Loss_G: 8.8427\n",
            "[0/25][105/782] Loss_D: 0.1389 Loss_G: 7.3863\n",
            "[0/25][106/782] Loss_D: 0.1155 Loss_G: 6.4500\n",
            "[0/25][107/782] Loss_D: 0.2869 Loss_G: 9.7958\n",
            "[0/25][108/782] Loss_D: 0.1613 Loss_G: 8.9079\n",
            "[0/25][109/782] Loss_D: 0.0413 Loss_G: 6.6020\n",
            "[0/25][110/782] Loss_D: 0.2455 Loss_G: 12.9458\n",
            "[0/25][111/782] Loss_D: 0.0490 Loss_G: 13.3627\n",
            "[0/25][112/782] Loss_D: 0.1157 Loss_G: 10.0162\n",
            "[0/25][113/782] Loss_D: 0.0495 Loss_G: 5.8728\n",
            "[0/25][114/782] Loss_D: 0.4327 Loss_G: 18.0655\n",
            "[0/25][115/782] Loss_D: 0.1672 Loss_G: 19.3059\n",
            "[0/25][116/782] Loss_D: 0.1826 Loss_G: 16.5599\n",
            "[0/25][117/782] Loss_D: 0.0508 Loss_G: 11.0736\n",
            "[0/25][118/782] Loss_D: 0.0239 Loss_G: 5.7664\n",
            "[0/25][119/782] Loss_D: 0.5757 Loss_G: 14.0401\n",
            "[0/25][120/782] Loss_D: 0.2474 Loss_G: 11.9333\n",
            "[0/25][121/782] Loss_D: 0.1226 Loss_G: 8.8974\n",
            "[0/25][122/782] Loss_D: 0.1565 Loss_G: 6.3634\n",
            "[0/25][123/782] Loss_D: 0.1693 Loss_G: 7.3372\n",
            "[0/25][124/782] Loss_D: 0.1984 Loss_G: 6.1514\n",
            "[0/25][125/782] Loss_D: 0.2290 Loss_G: 6.1996\n",
            "[0/25][126/782] Loss_D: 0.3460 Loss_G: 6.7342\n",
            "[0/25][127/782] Loss_D: 0.2704 Loss_G: 5.0656\n",
            "[0/25][128/782] Loss_D: 0.4528 Loss_G: 12.1698\n",
            "[0/25][129/782] Loss_D: 1.0464 Loss_G: 7.3565\n",
            "[0/25][130/782] Loss_D: 0.1827 Loss_G: 5.2324\n",
            "[0/25][131/782] Loss_D: 0.6841 Loss_G: 10.8038\n",
            "[0/25][132/782] Loss_D: 0.7917 Loss_G: 7.8767\n",
            "[0/25][133/782] Loss_D: 0.1307 Loss_G: 6.7120\n",
            "[0/25][134/782] Loss_D: 0.3311 Loss_G: 7.0788\n",
            "[0/25][135/782] Loss_D: 0.4848 Loss_G: 5.4449\n",
            "[0/25][136/782] Loss_D: 0.3875 Loss_G: 7.7092\n",
            "[0/25][137/782] Loss_D: 0.4714 Loss_G: 4.2831\n",
            "[0/25][138/782] Loss_D: 0.5793 Loss_G: 10.0947\n",
            "[0/25][139/782] Loss_D: 0.5465 Loss_G: 7.2189\n",
            "[0/25][140/782] Loss_D: 0.1067 Loss_G: 4.7832\n",
            "[0/25][141/782] Loss_D: 0.4522 Loss_G: 7.5089\n",
            "[0/25][142/782] Loss_D: 0.2651 Loss_G: 5.4054\n",
            "[0/25][143/782] Loss_D: 0.2715 Loss_G: 4.3317\n",
            "[0/25][144/782] Loss_D: 0.3776 Loss_G: 7.2244\n",
            "[0/25][145/782] Loss_D: 0.9506 Loss_G: 2.2842\n",
            "[0/25][146/782] Loss_D: 1.1286 Loss_G: 10.9373\n",
            "[0/25][147/782] Loss_D: 1.6671 Loss_G: 7.5986\n",
            "[0/25][148/782] Loss_D: 0.1685 Loss_G: 4.7598\n",
            "[0/25][149/782] Loss_D: 0.1879 Loss_G: 3.8079\n",
            "[0/25][150/782] Loss_D: 0.3205 Loss_G: 5.0386\n",
            "[0/25][151/782] Loss_D: 0.3120 Loss_G: 4.4918\n",
            "[0/25][152/782] Loss_D: 0.2142 Loss_G: 4.3800\n",
            "[0/25][153/782] Loss_D: 0.5106 Loss_G: 6.2711\n",
            "[0/25][154/782] Loss_D: 0.7017 Loss_G: 2.7165\n",
            "[0/25][155/782] Loss_D: 1.0046 Loss_G: 10.5735\n",
            "[0/25][156/782] Loss_D: 1.3990 Loss_G: 7.2924\n",
            "[0/25][157/782] Loss_D: 0.1426 Loss_G: 3.6296\n",
            "[0/25][158/782] Loss_D: 0.8792 Loss_G: 7.9367\n",
            "[0/25][159/782] Loss_D: 1.1348 Loss_G: 4.5954\n",
            "[0/25][160/782] Loss_D: 0.2998 Loss_G: 4.6367\n",
            "[0/25][161/782] Loss_D: 0.5929 Loss_G: 5.5469\n",
            "[0/25][162/782] Loss_D: 0.2852 Loss_G: 4.5603\n",
            "[0/25][163/782] Loss_D: 0.5878 Loss_G: 2.6312\n",
            "[0/25][164/782] Loss_D: 0.7594 Loss_G: 8.3635\n",
            "[0/25][165/782] Loss_D: 1.0759 Loss_G: 4.4515\n",
            "[0/25][166/782] Loss_D: 0.2738 Loss_G: 3.4874\n",
            "[0/25][167/782] Loss_D: 0.4767 Loss_G: 6.2449\n",
            "[0/25][168/782] Loss_D: 0.4121 Loss_G: 4.4682\n",
            "[0/25][169/782] Loss_D: 0.2419 Loss_G: 4.3918\n",
            "[0/25][170/782] Loss_D: 0.4961 Loss_G: 6.0456\n",
            "[0/25][171/782] Loss_D: 0.4785 Loss_G: 3.7153\n",
            "[0/25][172/782] Loss_D: 0.5944 Loss_G: 5.5035\n",
            "[0/25][173/782] Loss_D: 0.4971 Loss_G: 4.5482\n",
            "[0/25][174/782] Loss_D: 0.5896 Loss_G: 5.6319\n",
            "[0/25][175/782] Loss_D: 0.3059 Loss_G: 4.5422\n",
            "[0/25][176/782] Loss_D: 0.3364 Loss_G: 4.5588\n",
            "[0/25][177/782] Loss_D: 0.4245 Loss_G: 7.8162\n",
            "[0/25][178/782] Loss_D: 1.4665 Loss_G: 1.2165\n",
            "[0/25][179/782] Loss_D: 2.0109 Loss_G: 11.3390\n",
            "[0/25][180/782] Loss_D: 3.8163 Loss_G: 7.7047\n",
            "[0/25][181/782] Loss_D: 0.4470 Loss_G: 3.7198\n",
            "[0/25][182/782] Loss_D: 0.6037 Loss_G: 4.1389\n",
            "[0/25][183/782] Loss_D: 0.3854 Loss_G: 5.3966\n",
            "[0/25][184/782] Loss_D: 0.6005 Loss_G: 3.0436\n",
            "[0/25][185/782] Loss_D: 0.9156 Loss_G: 7.9356\n",
            "[0/25][186/782] Loss_D: 1.3000 Loss_G: 3.5829\n",
            "[0/25][187/782] Loss_D: 0.5365 Loss_G: 4.5100\n",
            "[0/25][188/782] Loss_D: 0.3952 Loss_G: 4.9059\n",
            "[0/25][189/782] Loss_D: 0.4646 Loss_G: 2.9328\n",
            "[0/25][190/782] Loss_D: 0.5255 Loss_G: 4.9618\n",
            "[0/25][191/782] Loss_D: 0.3575 Loss_G: 4.1381\n",
            "[0/25][192/782] Loss_D: 0.3612 Loss_G: 3.3611\n",
            "[0/25][193/782] Loss_D: 0.4902 Loss_G: 4.7456\n",
            "[0/25][194/782] Loss_D: 0.5554 Loss_G: 2.2735\n",
            "[0/25][195/782] Loss_D: 0.9517 Loss_G: 7.9647\n",
            "[0/25][196/782] Loss_D: 1.5785 Loss_G: 3.5349\n",
            "[0/25][197/782] Loss_D: 0.4034 Loss_G: 2.5640\n",
            "[0/25][198/782] Loss_D: 0.9877 Loss_G: 7.5094\n",
            "[0/25][199/782] Loss_D: 1.2151 Loss_G: 5.0569\n",
            "[0/25][200/782] Loss_D: 0.3528 Loss_G: 2.3449\n",
            "[0/25][201/782] Loss_D: 0.5663 Loss_G: 6.0926\n",
            "[0/25][202/782] Loss_D: 0.5065 Loss_G: 4.0879\n",
            "[0/25][203/782] Loss_D: 0.2257 Loss_G: 3.4516\n",
            "[0/25][204/782] Loss_D: 0.2852 Loss_G: 3.8555\n",
            "[0/25][205/782] Loss_D: 0.3412 Loss_G: 4.8287\n",
            "[0/25][206/782] Loss_D: 0.5537 Loss_G: 3.2079\n",
            "[0/25][207/782] Loss_D: 0.6046 Loss_G: 5.6228\n",
            "[0/25][208/782] Loss_D: 0.5656 Loss_G: 3.7280\n",
            "[0/25][209/782] Loss_D: 0.4000 Loss_G: 3.7641\n",
            "[0/25][210/782] Loss_D: 0.4719 Loss_G: 5.6359\n",
            "[0/25][211/782] Loss_D: 0.3784 Loss_G: 3.8404\n",
            "[0/25][212/782] Loss_D: 0.3124 Loss_G: 3.7374\n",
            "[0/25][213/782] Loss_D: 0.3827 Loss_G: 7.2398\n",
            "[0/25][214/782] Loss_D: 0.5444 Loss_G: 4.5650\n",
            "[0/25][215/782] Loss_D: 0.2402 Loss_G: 4.2076\n",
            "[0/25][216/782] Loss_D: 0.3374 Loss_G: 7.4678\n",
            "[0/25][217/782] Loss_D: 0.3448 Loss_G: 5.2477\n",
            "[0/25][218/782] Loss_D: 0.2698 Loss_G: 4.4695\n",
            "[0/25][219/782] Loss_D: 0.3152 Loss_G: 7.0010\n",
            "[0/25][220/782] Loss_D: 0.7469 Loss_G: 2.2117\n",
            "[0/25][221/782] Loss_D: 1.1482 Loss_G: 12.2102\n",
            "[0/25][222/782] Loss_D: 3.0375 Loss_G: 5.9207\n",
            "[0/25][223/782] Loss_D: 0.1829 Loss_G: 3.3612\n",
            "[0/25][224/782] Loss_D: 0.6164 Loss_G: 7.8619\n",
            "[0/25][225/782] Loss_D: 1.2625 Loss_G: 2.5797\n",
            "[0/25][226/782] Loss_D: 0.9218 Loss_G: 7.1667\n",
            "[0/25][227/782] Loss_D: 0.1497 Loss_G: 7.1615\n",
            "[0/25][228/782] Loss_D: 0.2496 Loss_G: 5.2780\n",
            "[0/25][229/782] Loss_D: 0.1970 Loss_G: 4.0279\n",
            "[0/25][230/782] Loss_D: 0.3058 Loss_G: 5.5540\n",
            "[0/25][231/782] Loss_D: 0.3354 Loss_G: 4.2442\n",
            "[0/25][232/782] Loss_D: 0.2871 Loss_G: 4.9765\n",
            "[0/25][233/782] Loss_D: 0.2045 Loss_G: 5.3990\n",
            "[0/25][234/782] Loss_D: 0.1482 Loss_G: 5.8408\n",
            "[0/25][235/782] Loss_D: 0.2710 Loss_G: 4.4736\n",
            "[0/25][236/782] Loss_D: 0.2307 Loss_G: 6.2163\n",
            "[0/25][237/782] Loss_D: 0.0977 Loss_G: 6.2508\n",
            "[0/25][238/782] Loss_D: 0.1073 Loss_G: 5.1111\n",
            "[0/25][239/782] Loss_D: 0.1639 Loss_G: 4.5341\n",
            "[0/25][240/782] Loss_D: 0.3199 Loss_G: 7.5653\n",
            "[0/25][241/782] Loss_D: 0.3416 Loss_G: 6.1689\n",
            "[0/25][242/782] Loss_D: 0.1695 Loss_G: 5.1192\n",
            "[0/25][243/782] Loss_D: 0.2321 Loss_G: 7.2382\n",
            "[0/25][244/782] Loss_D: 0.0909 Loss_G: 6.9427\n",
            "[0/25][245/782] Loss_D: 0.4261 Loss_G: 3.9414\n",
            "[0/25][246/782] Loss_D: 0.7717 Loss_G: 12.2570\n",
            "[0/25][247/782] Loss_D: 1.1879 Loss_G: 9.7680\n",
            "[0/25][248/782] Loss_D: 0.0738 Loss_G: 7.3603\n",
            "[0/25][249/782] Loss_D: 0.1684 Loss_G: 6.1394\n",
            "[0/25][250/782] Loss_D: 0.2075 Loss_G: 7.3079\n",
            "[0/25][251/782] Loss_D: 0.1676 Loss_G: 6.3958\n",
            "[0/25][252/782] Loss_D: 0.0714 Loss_G: 5.5243\n",
            "[0/25][253/782] Loss_D: 0.2055 Loss_G: 5.8284\n",
            "[0/25][254/782] Loss_D: 0.1667 Loss_G: 5.7539\n",
            "[0/25][255/782] Loss_D: 0.2101 Loss_G: 5.4547\n",
            "[0/25][256/782] Loss_D: 0.2267 Loss_G: 6.0150\n",
            "[0/25][257/782] Loss_D: 0.1148 Loss_G: 6.0246\n",
            "[0/25][258/782] Loss_D: 0.1985 Loss_G: 4.3640\n",
            "[0/25][259/782] Loss_D: 0.5854 Loss_G: 12.5611\n",
            "[0/25][260/782] Loss_D: 0.8423 Loss_G: 9.9072\n",
            "[0/25][261/782] Loss_D: 0.2362 Loss_G: 5.8372\n",
            "[0/25][262/782] Loss_D: 0.1905 Loss_G: 4.5878\n",
            "[0/25][263/782] Loss_D: 0.8795 Loss_G: 12.3193\n",
            "[0/25][264/782] Loss_D: 0.4829 Loss_G: 9.6525\n",
            "[0/25][265/782] Loss_D: 0.4005 Loss_G: 4.7528\n",
            "[0/25][266/782] Loss_D: 0.8667 Loss_G: 11.8931\n",
            "[0/25][267/782] Loss_D: 0.8701 Loss_G: 8.7358\n",
            "[0/25][268/782] Loss_D: 0.1045 Loss_G: 5.6435\n",
            "[0/25][269/782] Loss_D: 0.2884 Loss_G: 6.8110\n",
            "[0/25][270/782] Loss_D: 0.1864 Loss_G: 7.2091\n",
            "[0/25][271/782] Loss_D: 0.0721 Loss_G: 6.6077\n",
            "[0/25][272/782] Loss_D: 0.1685 Loss_G: 5.5867\n",
            "[0/25][273/782] Loss_D: 0.1558 Loss_G: 5.2077\n",
            "[0/25][274/782] Loss_D: 0.1802 Loss_G: 6.5331\n",
            "[0/25][275/782] Loss_D: 0.0530 Loss_G: 6.6135\n",
            "[0/25][276/782] Loss_D: 0.2609 Loss_G: 4.6482\n",
            "[0/25][277/782] Loss_D: 0.1830 Loss_G: 6.8595\n",
            "[0/25][278/782] Loss_D: 0.2740 Loss_G: 5.2594\n",
            "[0/25][279/782] Loss_D: 0.3313 Loss_G: 8.4846\n",
            "[0/25][280/782] Loss_D: 0.6841 Loss_G: 4.2905\n",
            "[0/25][281/782] Loss_D: 0.9263 Loss_G: 12.8257\n",
            "[0/25][282/782] Loss_D: 0.4674 Loss_G: 12.2601\n",
            "[0/25][283/782] Loss_D: 0.2131 Loss_G: 8.5281\n",
            "[0/25][284/782] Loss_D: 0.1638 Loss_G: 4.9364\n",
            "[0/25][285/782] Loss_D: 0.5009 Loss_G: 7.2048\n",
            "[0/25][286/782] Loss_D: 0.1476 Loss_G: 7.2110\n",
            "[0/25][287/782] Loss_D: 0.4984 Loss_G: 4.1054\n",
            "[0/25][288/782] Loss_D: 0.7423 Loss_G: 8.0569\n",
            "[0/25][289/782] Loss_D: 0.3797 Loss_G: 7.0587\n",
            "[0/25][290/782] Loss_D: 0.1743 Loss_G: 4.7351\n",
            "[0/25][291/782] Loss_D: 0.4811 Loss_G: 6.4911\n",
            "[0/25][292/782] Loss_D: 0.3461 Loss_G: 5.6162\n",
            "[0/25][293/782] Loss_D: 0.4469 Loss_G: 4.5843\n",
            "[0/25][294/782] Loss_D: 0.4653 Loss_G: 6.9284\n",
            "[0/25][295/782] Loss_D: 0.7319 Loss_G: 2.3219\n",
            "[0/25][296/782] Loss_D: 1.3012 Loss_G: 12.1033\n",
            "[0/25][297/782] Loss_D: 1.2168 Loss_G: 8.7729\n",
            "[0/25][298/782] Loss_D: 0.2686 Loss_G: 3.5267\n",
            "[0/25][299/782] Loss_D: 0.8990 Loss_G: 6.1893\n",
            "[0/25][300/782] Loss_D: 0.2801 Loss_G: 5.5483\n",
            "[0/25][301/782] Loss_D: 0.2106 Loss_G: 4.3685\n",
            "[0/25][302/782] Loss_D: 0.2188 Loss_G: 3.8459\n",
            "[0/25][303/782] Loss_D: 0.2225 Loss_G: 4.0704\n",
            "[0/25][304/782] Loss_D: 0.3089 Loss_G: 5.2172\n",
            "[0/25][305/782] Loss_D: 0.2026 Loss_G: 4.9575\n",
            "[0/25][306/782] Loss_D: 0.3473 Loss_G: 3.4830\n",
            "[0/25][307/782] Loss_D: 0.5503 Loss_G: 8.0293\n",
            "[0/25][308/782] Loss_D: 0.6169 Loss_G: 5.3800\n",
            "[0/25][309/782] Loss_D: 0.1776 Loss_G: 4.0020\n",
            "[0/25][310/782] Loss_D: 1.1699 Loss_G: 14.5467\n",
            "[0/25][311/782] Loss_D: 3.2276 Loss_G: 9.4071\n",
            "[0/25][312/782] Loss_D: 0.4811 Loss_G: 3.2125\n",
            "[0/25][313/782] Loss_D: 1.1845 Loss_G: 6.5886\n",
            "[0/25][314/782] Loss_D: 1.0496 Loss_G: 3.6546\n",
            "[0/25][315/782] Loss_D: 0.3713 Loss_G: 4.4107\n",
            "[0/25][316/782] Loss_D: 0.4230 Loss_G: 3.8913\n",
            "[0/25][317/782] Loss_D: 0.4682 Loss_G: 4.3497\n",
            "[0/25][318/782] Loss_D: 0.7625 Loss_G: 2.6564\n",
            "[0/25][319/782] Loss_D: 0.4639 Loss_G: 5.0233\n",
            "[0/25][320/782] Loss_D: 0.3509 Loss_G: 5.0691\n",
            "[0/25][321/782] Loss_D: 0.4799 Loss_G: 3.1027\n",
            "[0/25][322/782] Loss_D: 0.4689 Loss_G: 5.5146\n",
            "[0/25][323/782] Loss_D: 0.3873 Loss_G: 4.2824\n",
            "[0/25][324/782] Loss_D: 0.2428 Loss_G: 3.3566\n",
            "[0/25][325/782] Loss_D: 0.2481 Loss_G: 5.8149\n",
            "[0/25][326/782] Loss_D: 0.1725 Loss_G: 5.1126\n",
            "[0/25][327/782] Loss_D: 0.1690 Loss_G: 4.5257\n",
            "[0/25][328/782] Loss_D: 0.4024 Loss_G: 4.2542\n",
            "[0/25][329/782] Loss_D: 0.2780 Loss_G: 4.0839\n",
            "[0/25][330/782] Loss_D: 0.2481 Loss_G: 3.9297\n",
            "[0/25][331/782] Loss_D: 0.4735 Loss_G: 2.4220\n",
            "[0/25][332/782] Loss_D: 0.8490 Loss_G: 5.6055\n",
            "[0/25][333/782] Loss_D: 0.7005 Loss_G: 2.8382\n",
            "[0/25][334/782] Loss_D: 0.4114 Loss_G: 3.8628\n",
            "[0/25][335/782] Loss_D: 0.3840 Loss_G: 4.5437\n",
            "[0/25][336/782] Loss_D: 0.2352 Loss_G: 4.0745\n",
            "[0/25][337/782] Loss_D: 0.4340 Loss_G: 2.2384\n",
            "[0/25][338/782] Loss_D: 0.7553 Loss_G: 5.5829\n",
            "[0/25][339/782] Loss_D: 0.5113 Loss_G: 4.2095\n",
            "[0/25][340/782] Loss_D: 0.3219 Loss_G: 3.6612\n",
            "[0/25][341/782] Loss_D: 0.3585 Loss_G: 4.6450\n",
            "[0/25][342/782] Loss_D: 0.4328 Loss_G: 3.1861\n",
            "[0/25][343/782] Loss_D: 0.3869 Loss_G: 3.5217\n",
            "[0/25][344/782] Loss_D: 0.3338 Loss_G: 7.8594\n",
            "[0/25][345/782] Loss_D: 0.5174 Loss_G: 3.7494\n",
            "[0/25][346/782] Loss_D: 0.4845 Loss_G: 3.4627\n",
            "[0/25][347/782] Loss_D: 0.7892 Loss_G: 10.6248\n",
            "[0/25][348/782] Loss_D: 1.3375 Loss_G: 3.6627\n",
            "[0/25][349/782] Loss_D: 1.5050 Loss_G: 7.9206\n",
            "[0/25][350/782] Loss_D: 1.2985 Loss_G: 3.4095\n",
            "[0/25][351/782] Loss_D: 0.7090 Loss_G: 3.1851\n",
            "[0/25][352/782] Loss_D: 0.6904 Loss_G: 4.0259\n",
            "[0/25][353/782] Loss_D: 0.5911 Loss_G: 2.7108\n",
            "[0/25][354/782] Loss_D: 0.5832 Loss_G: 4.8416\n",
            "[0/25][355/782] Loss_D: 0.3431 Loss_G: 5.3433\n",
            "[0/25][356/782] Loss_D: 0.5245 Loss_G: 2.6995\n",
            "[0/25][357/782] Loss_D: 0.7349 Loss_G: 5.4250\n",
            "[0/25][358/782] Loss_D: 0.4683 Loss_G: 4.2205\n",
            "[0/25][359/782] Loss_D: 0.4049 Loss_G: 4.5318\n",
            "[0/25][360/782] Loss_D: 0.4612 Loss_G: 5.1522\n",
            "[0/25][361/782] Loss_D: 0.6281 Loss_G: 3.4235\n",
            "[0/25][362/782] Loss_D: 1.7372 Loss_G: 13.1364\n",
            "[0/25][363/782] Loss_D: 5.6232 Loss_G: 6.1583\n",
            "[0/25][364/782] Loss_D: 0.9566 Loss_G: 0.8310\n",
            "[0/25][365/782] Loss_D: 1.9782 Loss_G: 7.9491\n",
            "[0/25][366/782] Loss_D: 1.1639 Loss_G: 5.1290\n",
            "[0/25][367/782] Loss_D: 0.5797 Loss_G: 1.9264\n",
            "[0/25][368/782] Loss_D: 0.9843 Loss_G: 3.7480\n",
            "[0/25][369/782] Loss_D: 0.5346 Loss_G: 4.3932\n",
            "[0/25][370/782] Loss_D: 0.6932 Loss_G: 2.6569\n",
            "[0/25][371/782] Loss_D: 0.7767 Loss_G: 3.2342\n",
            "[0/25][372/782] Loss_D: 0.6346 Loss_G: 2.9798\n",
            "[0/25][373/782] Loss_D: 0.8015 Loss_G: 3.4353\n",
            "[0/25][374/782] Loss_D: 0.8487 Loss_G: 4.2216\n",
            "[0/25][375/782] Loss_D: 0.8733 Loss_G: 2.3449\n",
            "[0/25][376/782] Loss_D: 0.6061 Loss_G: 4.5807\n",
            "[0/25][377/782] Loss_D: 0.4336 Loss_G: 3.7042\n",
            "[0/25][378/782] Loss_D: 0.4292 Loss_G: 3.1224\n",
            "[0/25][379/782] Loss_D: 0.2896 Loss_G: 5.0855\n",
            "[0/25][380/782] Loss_D: 0.2853 Loss_G: 4.6667\n",
            "[0/25][381/782] Loss_D: 0.2923 Loss_G: 3.6832\n",
            "[0/25][382/782] Loss_D: 0.3227 Loss_G: 3.8696\n",
            "[0/25][383/782] Loss_D: 0.3681 Loss_G: 5.4387\n",
            "[0/25][384/782] Loss_D: 0.3379 Loss_G: 3.7590\n",
            "[0/25][385/782] Loss_D: 0.4211 Loss_G: 4.6731\n",
            "[0/25][386/782] Loss_D: 0.3833 Loss_G: 3.3087\n",
            "[0/25][387/782] Loss_D: 0.6688 Loss_G: 5.7395\n",
            "[0/25][388/782] Loss_D: 0.8534 Loss_G: 1.5116\n",
            "[0/25][389/782] Loss_D: 1.3873 Loss_G: 7.4902\n",
            "[0/25][390/782] Loss_D: 1.9796 Loss_G: 2.2974\n",
            "[0/25][391/782] Loss_D: 0.8499 Loss_G: 4.6243\n",
            "[0/25][392/782] Loss_D: 0.5920 Loss_G: 2.6137\n",
            "[0/25][393/782] Loss_D: 1.0189 Loss_G: 8.0075\n",
            "[0/25][394/782] Loss_D: 1.6564 Loss_G: 2.3258\n",
            "[0/25][395/782] Loss_D: 0.6791 Loss_G: 4.7578\n",
            "[0/25][396/782] Loss_D: 0.5361 Loss_G: 3.7398\n",
            "[0/25][397/782] Loss_D: 0.4667 Loss_G: 2.9082\n",
            "[0/25][398/782] Loss_D: 0.5396 Loss_G: 5.1862\n",
            "[0/25][399/782] Loss_D: 0.3790 Loss_G: 4.3119\n",
            "[0/25][400/782] Loss_D: 0.4273 Loss_G: 3.0018\n",
            "[0/25][401/782] Loss_D: 0.7742 Loss_G: 4.2375\n",
            "[0/25][402/782] Loss_D: 0.5897 Loss_G: 3.6431\n",
            "[0/25][403/782] Loss_D: 0.5929 Loss_G: 3.2116\n",
            "[0/25][404/782] Loss_D: 0.5251 Loss_G: 5.0017\n",
            "[0/25][405/782] Loss_D: 0.6340 Loss_G: 2.9333\n",
            "[0/25][406/782] Loss_D: 0.5621 Loss_G: 5.4105\n",
            "[0/25][407/782] Loss_D: 0.5031 Loss_G: 3.6965\n",
            "[0/25][408/782] Loss_D: 0.4662 Loss_G: 3.5706\n",
            "[0/25][409/782] Loss_D: 0.5556 Loss_G: 4.8748\n",
            "[0/25][410/782] Loss_D: 0.2427 Loss_G: 4.6235\n",
            "[0/25][411/782] Loss_D: 0.4138 Loss_G: 3.6010\n",
            "[0/25][412/782] Loss_D: 0.5926 Loss_G: 5.5213\n",
            "[0/25][413/782] Loss_D: 0.4388 Loss_G: 3.7225\n",
            "[0/25][414/782] Loss_D: 0.6584 Loss_G: 5.6803\n",
            "[0/25][415/782] Loss_D: 0.4772 Loss_G: 3.7607\n",
            "[0/25][416/782] Loss_D: 0.4784 Loss_G: 6.9550\n",
            "[0/25][417/782] Loss_D: 0.8723 Loss_G: 2.6874\n",
            "[0/25][418/782] Loss_D: 1.0588 Loss_G: 8.6062\n",
            "[0/25][419/782] Loss_D: 1.0641 Loss_G: 1.7112\n",
            "[0/25][420/782] Loss_D: 1.4966 Loss_G: 11.8169\n",
            "[0/25][421/782] Loss_D: 3.1151 Loss_G: 3.6038\n",
            "[0/25][422/782] Loss_D: 0.8689 Loss_G: 4.9392\n",
            "[0/25][423/782] Loss_D: 0.6878 Loss_G: 3.4137\n",
            "[0/25][424/782] Loss_D: 0.6433 Loss_G: 3.7877\n",
            "[0/25][425/782] Loss_D: 0.7216 Loss_G: 3.6806\n",
            "[0/25][426/782] Loss_D: 1.0191 Loss_G: 3.5393\n",
            "[0/25][427/782] Loss_D: 1.2482 Loss_G: 3.8144\n",
            "[0/25][428/782] Loss_D: 0.8928 Loss_G: 3.7278\n",
            "[0/25][429/782] Loss_D: 0.5047 Loss_G: 5.7622\n",
            "[0/25][430/782] Loss_D: 0.2557 Loss_G: 4.9956\n",
            "[0/25][431/782] Loss_D: 0.2924 Loss_G: 3.7501\n",
            "[0/25][432/782] Loss_D: 0.3928 Loss_G: 6.0080\n",
            "[0/25][433/782] Loss_D: 0.4254 Loss_G: 3.5025\n",
            "[0/25][434/782] Loss_D: 0.5076 Loss_G: 4.7812\n",
            "[0/25][435/782] Loss_D: 0.5535 Loss_G: 2.7316\n",
            "[0/25][436/782] Loss_D: 0.4154 Loss_G: 4.6882\n",
            "[0/25][437/782] Loss_D: 0.1419 Loss_G: 5.1406\n",
            "[0/25][438/782] Loss_D: 0.2014 Loss_G: 4.1645\n",
            "[0/25][439/782] Loss_D: 0.2310 Loss_G: 3.2257\n",
            "[0/25][440/782] Loss_D: 0.3335 Loss_G: 4.6522\n",
            "[0/25][441/782] Loss_D: 0.2689 Loss_G: 4.3425\n",
            "[0/25][442/782] Loss_D: 0.2259 Loss_G: 3.7819\n",
            "[0/25][443/782] Loss_D: 0.3592 Loss_G: 4.5847\n",
            "[0/25][444/782] Loss_D: 0.2614 Loss_G: 4.0550\n",
            "[0/25][445/782] Loss_D: 0.2427 Loss_G: 4.5340\n",
            "[0/25][446/782] Loss_D: 0.3755 Loss_G: 3.2918\n",
            "[0/25][447/782] Loss_D: 0.4678 Loss_G: 6.3434\n",
            "[0/25][448/782] Loss_D: 0.4087 Loss_G: 4.1303\n",
            "[0/25][449/782] Loss_D: 0.3915 Loss_G: 3.4321\n",
            "[0/25][450/782] Loss_D: 0.4546 Loss_G: 7.9208\n",
            "[0/25][451/782] Loss_D: 0.7496 Loss_G: 3.9449\n",
            "[0/25][452/782] Loss_D: 0.3086 Loss_G: 6.2265\n",
            "[0/25][453/782] Loss_D: 0.1810 Loss_G: 5.9284\n",
            "[0/25][454/782] Loss_D: 0.3078 Loss_G: 4.1338\n",
            "[0/25][455/782] Loss_D: 0.4845 Loss_G: 7.2573\n",
            "[0/25][456/782] Loss_D: 0.2141 Loss_G: 4.7859\n",
            "[0/25][457/782] Loss_D: 0.4100 Loss_G: 8.6143\n",
            "[0/25][458/782] Loss_D: 1.2258 Loss_G: 0.1970\n",
            "[0/25][459/782] Loss_D: 3.5643 Loss_G: 10.8124\n",
            "[0/25][460/782] Loss_D: 3.5878 Loss_G: 0.6496\n",
            "[0/25][461/782] Loss_D: 2.1238 Loss_G: 7.2697\n",
            "[0/25][462/782] Loss_D: 2.3206 Loss_G: 2.9695\n",
            "[0/25][463/782] Loss_D: 0.8094 Loss_G: 2.4149\n",
            "[0/25][464/782] Loss_D: 1.0734 Loss_G: 4.0522\n",
            "[0/25][465/782] Loss_D: 0.8113 Loss_G: 3.2731\n",
            "[0/25][466/782] Loss_D: 0.7735 Loss_G: 2.3620\n",
            "[0/25][467/782] Loss_D: 1.1295 Loss_G: 2.8233\n",
            "[0/25][468/782] Loss_D: 1.0176 Loss_G: 2.4641\n",
            "[0/25][469/782] Loss_D: 1.2614 Loss_G: 3.0349\n",
            "[0/25][470/782] Loss_D: 0.9725 Loss_G: 2.3343\n",
            "[0/25][471/782] Loss_D: 1.1537 Loss_G: 2.8661\n",
            "[0/25][472/782] Loss_D: 0.7923 Loss_G: 3.3525\n",
            "[0/25][473/782] Loss_D: 0.5496 Loss_G: 2.8796\n",
            "[0/25][474/782] Loss_D: 0.8725 Loss_G: 3.8560\n",
            "[0/25][475/782] Loss_D: 0.7155 Loss_G: 2.7598\n",
            "[0/25][476/782] Loss_D: 0.8810 Loss_G: 2.9640\n",
            "[0/25][477/782] Loss_D: 0.7313 Loss_G: 4.0782\n",
            "[0/25][478/782] Loss_D: 0.9347 Loss_G: 1.3508\n",
            "[0/25][479/782] Loss_D: 1.2967 Loss_G: 5.7951\n",
            "[0/25][480/782] Loss_D: 1.6887 Loss_G: 1.5279\n",
            "[0/25][481/782] Loss_D: 0.8711 Loss_G: 3.8685\n",
            "[0/25][482/782] Loss_D: 0.3973 Loss_G: 3.9145\n",
            "[0/25][483/782] Loss_D: 0.5726 Loss_G: 2.6565\n",
            "[0/25][484/782] Loss_D: 0.7383 Loss_G: 3.4329\n",
            "[0/25][485/782] Loss_D: 0.6260 Loss_G: 3.5880\n",
            "[0/25][486/782] Loss_D: 0.6247 Loss_G: 2.2988\n",
            "[0/25][487/782] Loss_D: 0.5380 Loss_G: 3.1428\n",
            "[0/25][488/782] Loss_D: 0.6823 Loss_G: 2.8861\n",
            "[0/25][489/782] Loss_D: 0.5696 Loss_G: 3.3503\n",
            "[0/25][490/782] Loss_D: 0.5848 Loss_G: 2.9073\n",
            "[0/25][491/782] Loss_D: 0.6557 Loss_G: 4.9094\n",
            "[0/25][492/782] Loss_D: 1.4525 Loss_G: 0.3792\n",
            "[0/25][493/782] Loss_D: 2.8713 Loss_G: 7.4728\n",
            "[0/25][494/782] Loss_D: 2.1607 Loss_G: 2.6329\n",
            "[0/25][495/782] Loss_D: 0.5988 Loss_G: 2.1658\n",
            "[0/25][496/782] Loss_D: 0.6629 Loss_G: 4.5892\n",
            "[0/25][497/782] Loss_D: 0.5467 Loss_G: 3.6719\n",
            "[0/25][498/782] Loss_D: 0.3358 Loss_G: 2.8919\n",
            "[0/25][499/782] Loss_D: 0.4130 Loss_G: 3.7968\n",
            "[0/25][500/782] Loss_D: 0.3924 Loss_G: 3.6841\n",
            "[0/25][501/782] Loss_D: 0.3258 Loss_G: 3.5946\n",
            "[0/25][502/782] Loss_D: 0.3084 Loss_G: 3.3392\n",
            "[0/25][503/782] Loss_D: 0.3364 Loss_G: 3.8589\n",
            "[0/25][504/782] Loss_D: 0.3470 Loss_G: 3.6577\n",
            "[0/25][505/782] Loss_D: 0.3432 Loss_G: 3.0160\n",
            "[0/25][506/782] Loss_D: 0.4563 Loss_G: 2.9424\n",
            "[0/25][507/782] Loss_D: 0.5292 Loss_G: 3.6293\n",
            "[0/25][508/782] Loss_D: 0.4411 Loss_G: 2.6403\n",
            "[0/25][509/782] Loss_D: 0.7688 Loss_G: 5.5300\n",
            "[0/25][510/782] Loss_D: 1.6280 Loss_G: 0.9844\n",
            "[0/25][511/782] Loss_D: 1.6298 Loss_G: 6.8450\n",
            "[0/25][512/782] Loss_D: 1.2238 Loss_G: 3.0479\n",
            "[0/25][513/782] Loss_D: 0.4136 Loss_G: 3.2828\n",
            "[0/25][514/782] Loss_D: 0.4032 Loss_G: 4.5791\n",
            "[0/25][515/782] Loss_D: 0.6658 Loss_G: 2.2759\n",
            "[0/25][516/782] Loss_D: 0.3935 Loss_G: 3.0666\n",
            "[0/25][517/782] Loss_D: 0.4611 Loss_G: 4.2882\n",
            "[0/25][518/782] Loss_D: 0.4808 Loss_G: 2.8191\n",
            "[0/25][519/782] Loss_D: 0.4579 Loss_G: 2.9989\n",
            "[0/25][520/782] Loss_D: 0.4894 Loss_G: 3.7780\n",
            "[0/25][521/782] Loss_D: 0.3078 Loss_G: 3.6331\n",
            "[0/25][522/782] Loss_D: 0.3742 Loss_G: 2.7975\n",
            "[0/25][523/782] Loss_D: 0.4113 Loss_G: 4.4640\n",
            "[0/25][524/782] Loss_D: 0.1595 Loss_G: 4.7099\n",
            "[0/25][525/782] Loss_D: 0.3550 Loss_G: 2.6788\n",
            "[0/25][526/782] Loss_D: 0.3381 Loss_G: 3.8152\n",
            "[0/25][527/782] Loss_D: 0.2923 Loss_G: 4.1235\n",
            "[0/25][528/782] Loss_D: 0.4144 Loss_G: 3.0060\n",
            "[0/25][529/782] Loss_D: 0.3809 Loss_G: 4.1704\n",
            "[0/25][530/782] Loss_D: 0.1785 Loss_G: 4.2439\n",
            "[0/25][531/782] Loss_D: 0.2533 Loss_G: 3.3575\n",
            "[0/25][532/782] Loss_D: 0.5025 Loss_G: 4.2451\n",
            "[0/25][533/782] Loss_D: 0.3895 Loss_G: 3.0233\n",
            "[0/25][534/782] Loss_D: 0.4932 Loss_G: 6.2605\n",
            "[0/25][535/782] Loss_D: 0.3883 Loss_G: 4.2993\n",
            "[0/25][536/782] Loss_D: 0.2834 Loss_G: 2.6009\n",
            "[0/25][537/782] Loss_D: 0.4383 Loss_G: 6.4873\n",
            "[0/25][538/782] Loss_D: 0.3140 Loss_G: 4.6200\n",
            "[0/25][539/782] Loss_D: 0.1641 Loss_G: 3.7044\n",
            "[0/25][540/782] Loss_D: 0.2935 Loss_G: 5.8642\n",
            "[0/25][541/782] Loss_D: 0.2018 Loss_G: 5.1295\n",
            "[0/25][542/782] Loss_D: 0.2197 Loss_G: 3.6212\n",
            "[0/25][543/782] Loss_D: 0.3333 Loss_G: 5.2392\n",
            "[0/25][544/782] Loss_D: 0.2532 Loss_G: 4.2410\n",
            "[0/25][545/782] Loss_D: 0.3310 Loss_G: 4.3188\n",
            "[0/25][546/782] Loss_D: 0.3131 Loss_G: 6.7549\n",
            "[0/25][547/782] Loss_D: 0.4780 Loss_G: 3.9042\n",
            "[0/25][548/782] Loss_D: 0.9668 Loss_G: 9.8187\n",
            "[0/25][549/782] Loss_D: 1.2863 Loss_G: 5.2216\n",
            "[0/25][550/782] Loss_D: 0.4166 Loss_G: 5.9607\n",
            "[0/25][551/782] Loss_D: 0.2303 Loss_G: 6.4013\n",
            "[0/25][552/782] Loss_D: 0.0799 Loss_G: 6.0677\n",
            "[0/25][553/782] Loss_D: 0.2065 Loss_G: 4.6617\n",
            "[0/25][554/782] Loss_D: 0.2482 Loss_G: 5.3569\n",
            "[0/25][555/782] Loss_D: 0.1481 Loss_G: 4.8291\n",
            "[0/25][556/782] Loss_D: 0.3045 Loss_G: 4.9362\n",
            "[0/25][557/782] Loss_D: 0.2939 Loss_G: 3.7197\n",
            "[0/25][558/782] Loss_D: 0.4250 Loss_G: 5.5133\n",
            "[0/25][559/782] Loss_D: 0.6069 Loss_G: 3.1514\n",
            "[0/25][560/782] Loss_D: 0.6744 Loss_G: 9.3323\n",
            "[0/25][561/782] Loss_D: 1.0852 Loss_G: 3.3600\n",
            "[0/25][562/782] Loss_D: 0.8995 Loss_G: 8.0288\n",
            "[0/25][563/782] Loss_D: 0.5005 Loss_G: 5.0904\n",
            "[0/25][564/782] Loss_D: 0.2893 Loss_G: 3.6901\n",
            "[0/25][565/782] Loss_D: 0.6658 Loss_G: 8.3541\n",
            "[0/25][566/782] Loss_D: 0.8780 Loss_G: 3.7580\n",
            "[0/25][567/782] Loss_D: 0.4514 Loss_G: 4.9100\n",
            "[0/25][568/782] Loss_D: 0.3862 Loss_G: 4.8829\n",
            "[0/25][569/782] Loss_D: 0.2674 Loss_G: 3.8624\n",
            "[0/25][570/782] Loss_D: 0.2735 Loss_G: 4.6323\n",
            "[0/25][571/782] Loss_D: 0.2360 Loss_G: 3.8293\n",
            "[0/25][572/782] Loss_D: 0.3199 Loss_G: 4.5276\n",
            "[0/25][573/782] Loss_D: 0.1818 Loss_G: 4.9514\n",
            "[0/25][574/782] Loss_D: 0.2485 Loss_G: 5.3787\n",
            "[0/25][575/782] Loss_D: 0.5147 Loss_G: 1.9696\n",
            "[0/25][576/782] Loss_D: 1.1693 Loss_G: 11.0604\n",
            "[0/25][577/782] Loss_D: 2.3687 Loss_G: 4.6109\n",
            "[0/25][578/782] Loss_D: 0.4657 Loss_G: 4.2737\n",
            "[0/25][579/782] Loss_D: 0.3090 Loss_G: 6.5614\n",
            "[0/25][580/782] Loss_D: 0.2309 Loss_G: 4.4828\n",
            "[0/25][581/782] Loss_D: 0.3138 Loss_G: 5.6492\n",
            "[0/25][582/782] Loss_D: 0.4216 Loss_G: 3.5851\n",
            "[0/25][583/782] Loss_D: 0.3234 Loss_G: 5.2124\n",
            "[0/25][584/782] Loss_D: 0.2623 Loss_G: 4.5546\n",
            "[0/25][585/782] Loss_D: 0.2736 Loss_G: 3.5746\n",
            "[0/25][586/782] Loss_D: 0.4900 Loss_G: 7.2179\n",
            "[0/25][587/782] Loss_D: 0.7617 Loss_G: 2.6600\n",
            "[0/25][588/782] Loss_D: 0.4743 Loss_G: 6.1087\n",
            "[0/25][589/782] Loss_D: 0.1693 Loss_G: 5.1411\n",
            "[0/25][590/782] Loss_D: 0.3070 Loss_G: 3.3148\n",
            "[0/25][591/782] Loss_D: 0.3987 Loss_G: 6.6478\n",
            "[0/25][592/782] Loss_D: 0.6792 Loss_G: 1.8361\n",
            "[0/25][593/782] Loss_D: 0.6536 Loss_G: 8.6346\n",
            "[0/25][594/782] Loss_D: 0.4414 Loss_G: 4.3000\n",
            "[0/25][595/782] Loss_D: 0.1957 Loss_G: 5.6089\n",
            "[0/25][596/782] Loss_D: 0.2352 Loss_G: 6.3735\n",
            "[0/25][597/782] Loss_D: 0.2866 Loss_G: 4.1422\n",
            "[0/25][598/782] Loss_D: 0.5778 Loss_G: 6.8184\n",
            "[0/25][599/782] Loss_D: 1.0057 Loss_G: 1.9773\n",
            "[0/25][600/782] Loss_D: 1.2973 Loss_G: 8.5256\n",
            "[0/25][601/782] Loss_D: 0.9999 Loss_G: 3.1149\n",
            "[0/25][602/782] Loss_D: 0.6892 Loss_G: 10.0859\n",
            "[0/25][603/782] Loss_D: 0.9390 Loss_G: 4.1428\n",
            "[0/25][604/782] Loss_D: 0.3308 Loss_G: 3.1780\n",
            "[0/25][605/782] Loss_D: 0.7584 Loss_G: 8.6866\n",
            "[0/25][606/782] Loss_D: 0.7840 Loss_G: 4.5966\n",
            "[0/25][607/782] Loss_D: 0.3470 Loss_G: 3.6896\n",
            "[0/25][608/782] Loss_D: 0.3981 Loss_G: 6.4043\n",
            "[0/25][609/782] Loss_D: 0.3128 Loss_G: 5.0019\n",
            "[0/25][610/782] Loss_D: 0.2199 Loss_G: 3.7519\n",
            "[0/25][611/782] Loss_D: 0.4061 Loss_G: 6.5248\n",
            "[0/25][612/782] Loss_D: 0.5196 Loss_G: 3.9420\n",
            "[0/25][613/782] Loss_D: 0.2849 Loss_G: 3.7827\n",
            "[0/25][614/782] Loss_D: 0.3390 Loss_G: 6.6602\n",
            "[0/25][615/782] Loss_D: 0.6113 Loss_G: 3.8297\n",
            "[0/25][616/782] Loss_D: 0.3665 Loss_G: 5.3623\n",
            "[0/25][617/782] Loss_D: 0.5041 Loss_G: 3.3497\n",
            "[0/25][618/782] Loss_D: 0.3716 Loss_G: 5.9120\n",
            "[0/25][619/782] Loss_D: 0.1993 Loss_G: 4.9308\n",
            "[0/25][620/782] Loss_D: 0.2887 Loss_G: 4.4913\n",
            "[0/25][621/782] Loss_D: 0.1961 Loss_G: 4.5088\n",
            "[0/25][622/782] Loss_D: 0.2159 Loss_G: 4.6147\n",
            "[0/25][623/782] Loss_D: 0.1690 Loss_G: 4.7851\n",
            "[0/25][624/782] Loss_D: 0.2797 Loss_G: 3.5042\n",
            "[0/25][625/782] Loss_D: 0.4048 Loss_G: 4.8342\n",
            "[0/25][626/782] Loss_D: 0.1880 Loss_G: 4.5565\n",
            "[0/25][627/782] Loss_D: 0.1836 Loss_G: 4.5230\n",
            "[0/25][628/782] Loss_D: 0.1250 Loss_G: 4.5311\n",
            "[0/25][629/782] Loss_D: 0.1610 Loss_G: 3.9993\n",
            "[0/25][630/782] Loss_D: 0.1045 Loss_G: 4.3962\n",
            "[0/25][631/782] Loss_D: 0.1799 Loss_G: 4.9414\n",
            "[0/25][632/782] Loss_D: 0.1516 Loss_G: 4.2804\n",
            "[0/25][633/782] Loss_D: 0.1462 Loss_G: 4.1536\n",
            "[0/25][634/782] Loss_D: 0.2049 Loss_G: 3.8669\n",
            "[0/25][635/782] Loss_D: 0.3110 Loss_G: 4.7808\n",
            "[0/25][636/782] Loss_D: 0.1182 Loss_G: 4.9209\n",
            "[0/25][637/782] Loss_D: 0.1936 Loss_G: 3.4660\n",
            "[0/25][638/782] Loss_D: 0.3415 Loss_G: 6.9782\n",
            "[0/25][639/782] Loss_D: 0.0957 Loss_G: 7.4907\n",
            "[0/25][640/782] Loss_D: 0.2162 Loss_G: 4.6331\n",
            "[0/25][641/782] Loss_D: 0.6416 Loss_G: 7.1385\n",
            "[0/25][642/782] Loss_D: 0.4211 Loss_G: 1.9154\n",
            "[0/25][643/782] Loss_D: 1.0652 Loss_G: 14.2251\n",
            "[0/25][644/782] Loss_D: 2.8543 Loss_G: 0.6553\n",
            "[0/25][645/782] Loss_D: 4.1759 Loss_G: 9.3768\n",
            "[0/25][646/782] Loss_D: 1.4808 Loss_G: 5.7463\n",
            "[0/25][647/782] Loss_D: 0.9109 Loss_G: 1.9686\n",
            "[0/25][648/782] Loss_D: 1.2858 Loss_G: 4.6163\n",
            "[0/25][649/782] Loss_D: 0.6312 Loss_G: 5.1032\n",
            "[0/25][650/782] Loss_D: 0.6927 Loss_G: 2.9457\n",
            "[0/25][651/782] Loss_D: 1.0406 Loss_G: 5.3250\n",
            "[0/25][652/782] Loss_D: 0.9022 Loss_G: 2.7031\n",
            "[0/25][653/782] Loss_D: 0.6342 Loss_G: 5.0330\n",
            "[0/25][654/782] Loss_D: 0.5303 Loss_G: 3.1396\n",
            "[0/25][655/782] Loss_D: 0.6425 Loss_G: 5.3876\n",
            "[0/25][656/782] Loss_D: 0.2591 Loss_G: 5.2604\n",
            "[0/25][657/782] Loss_D: 0.2312 Loss_G: 3.7685\n",
            "[0/25][658/782] Loss_D: 0.4184 Loss_G: 3.9055\n",
            "[0/25][659/782] Loss_D: 0.3541 Loss_G: 4.1984\n",
            "[0/25][660/782] Loss_D: 0.3841 Loss_G: 4.2155\n",
            "[0/25][661/782] Loss_D: 0.3099 Loss_G: 3.7132\n",
            "[0/25][662/782] Loss_D: 0.3058 Loss_G: 4.5336\n",
            "[0/25][663/782] Loss_D: 0.2280 Loss_G: 4.3152\n",
            "[0/25][664/782] Loss_D: 0.3197 Loss_G: 3.8871\n",
            "[0/25][665/782] Loss_D: 0.2670 Loss_G: 5.1909\n",
            "[0/25][666/782] Loss_D: 0.2325 Loss_G: 4.7343\n",
            "[0/25][667/782] Loss_D: 0.3973 Loss_G: 3.3912\n",
            "[0/25][668/782] Loss_D: 0.7765 Loss_G: 7.7419\n",
            "[0/25][669/782] Loss_D: 0.7513 Loss_G: 3.6114\n",
            "[0/25][670/782] Loss_D: 0.5186 Loss_G: 6.8234\n",
            "[0/25][671/782] Loss_D: 0.4866 Loss_G: 4.5598\n",
            "[0/25][672/782] Loss_D: 0.4961 Loss_G: 4.3279\n",
            "[0/25][673/782] Loss_D: 0.6534 Loss_G: 3.5787\n",
            "[0/25][674/782] Loss_D: 0.2725 Loss_G: 5.0623\n",
            "[0/25][675/782] Loss_D: 0.5389 Loss_G: 3.0449\n",
            "[0/25][676/782] Loss_D: 0.3689 Loss_G: 5.8290\n",
            "[0/25][677/782] Loss_D: 0.3572 Loss_G: 4.6372\n",
            "[0/25][678/782] Loss_D: 0.1895 Loss_G: 4.0956\n",
            "[0/25][679/782] Loss_D: 0.3705 Loss_G: 4.7467\n",
            "[0/25][680/782] Loss_D: 0.2798 Loss_G: 5.1084\n",
            "[0/25][681/782] Loss_D: 0.3718 Loss_G: 4.5589\n",
            "[0/25][682/782] Loss_D: 0.6068 Loss_G: 4.6214\n",
            "[0/25][683/782] Loss_D: 0.2994 Loss_G: 5.5159\n",
            "[0/25][684/782] Loss_D: 0.1773 Loss_G: 5.5625\n",
            "[0/25][685/782] Loss_D: 0.1585 Loss_G: 5.9432\n",
            "[0/25][686/782] Loss_D: 0.2448 Loss_G: 6.0870\n",
            "[0/25][687/782] Loss_D: 0.4596 Loss_G: 4.3097\n",
            "[0/25][688/782] Loss_D: 0.6347 Loss_G: 5.6777\n",
            "[0/25][689/782] Loss_D: 0.1930 Loss_G: 6.2389\n",
            "[0/25][690/782] Loss_D: 0.2074 Loss_G: 5.5704\n",
            "[0/25][691/782] Loss_D: 0.4870 Loss_G: 3.4339\n",
            "[0/25][692/782] Loss_D: 0.8383 Loss_G: 7.1878\n",
            "[0/25][693/782] Loss_D: 0.7674 Loss_G: 3.8186\n",
            "[0/25][694/782] Loss_D: 0.9490 Loss_G: 8.4681\n",
            "[0/25][695/782] Loss_D: 0.7492 Loss_G: 4.4328\n",
            "[0/25][696/782] Loss_D: 1.1375 Loss_G: 11.5067\n",
            "[0/25][697/782] Loss_D: 1.5384 Loss_G: 4.1985\n",
            "[0/25][698/782] Loss_D: 0.8930 Loss_G: 6.8704\n",
            "[0/25][699/782] Loss_D: 0.4560 Loss_G: 6.1692\n",
            "[0/25][700/782] Loss_D: 0.3217 Loss_G: 5.4607\n",
            "[0/25][701/782] Loss_D: 0.5600 Loss_G: 8.2476\n",
            "[0/25][702/782] Loss_D: 0.7050 Loss_G: 3.5497\n",
            "[0/25][703/782] Loss_D: 0.9237 Loss_G: 9.2150\n",
            "[0/25][704/782] Loss_D: 1.1106 Loss_G: 3.8259\n",
            "[0/25][705/782] Loss_D: 0.7104 Loss_G: 5.8871\n",
            "[0/25][706/782] Loss_D: 0.7623 Loss_G: 5.4803\n",
            "[0/25][707/782] Loss_D: 0.3667 Loss_G: 4.2927\n",
            "[0/25][708/782] Loss_D: 0.4700 Loss_G: 6.3884\n",
            "[0/25][709/782] Loss_D: 0.3116 Loss_G: 4.8970\n",
            "[0/25][710/782] Loss_D: 0.5656 Loss_G: 3.1624\n",
            "[0/25][711/782] Loss_D: 0.9734 Loss_G: 7.4713\n",
            "[0/25][712/782] Loss_D: 0.9631 Loss_G: 1.7489\n",
            "[0/25][713/782] Loss_D: 1.3055 Loss_G: 9.2976\n",
            "[0/25][714/782] Loss_D: 1.5727 Loss_G: 2.9806\n",
            "[0/25][715/782] Loss_D: 0.7914 Loss_G: 8.0761\n",
            "[0/25][716/782] Loss_D: 0.6706 Loss_G: 5.5123\n",
            "[0/25][717/782] Loss_D: 0.7568 Loss_G: 0.9472\n",
            "[0/25][718/782] Loss_D: 1.2394 Loss_G: 6.1215\n",
            "[0/25][719/782] Loss_D: 0.7357 Loss_G: 3.6943\n",
            "[0/25][720/782] Loss_D: 0.2985 Loss_G: 2.7670\n",
            "[0/25][721/782] Loss_D: 0.8028 Loss_G: 6.6598\n",
            "[0/25][722/782] Loss_D: 0.9894 Loss_G: 3.2400\n",
            "[0/25][723/782] Loss_D: 0.8610 Loss_G: 1.4096\n",
            "[0/25][724/782] Loss_D: 1.1238 Loss_G: 5.7532\n",
            "[0/25][725/782] Loss_D: 1.5070 Loss_G: 1.5779\n",
            "[0/25][726/782] Loss_D: 0.8858 Loss_G: 4.2246\n",
            "[0/25][727/782] Loss_D: 0.1740 Loss_G: 4.8014\n",
            "[0/25][728/782] Loss_D: 0.9260 Loss_G: 0.7183\n",
            "[0/25][729/782] Loss_D: 1.6366 Loss_G: 6.4177\n",
            "[0/25][730/782] Loss_D: 1.7811 Loss_G: 2.5261\n",
            "[0/25][731/782] Loss_D: 0.7545 Loss_G: 2.9730\n",
            "[0/25][732/782] Loss_D: 0.5989 Loss_G: 3.1911\n",
            "[0/25][733/782] Loss_D: 0.4310 Loss_G: 2.9312\n",
            "[0/25][734/782] Loss_D: 0.3347 Loss_G: 3.5064\n",
            "[0/25][735/782] Loss_D: 0.5599 Loss_G: 3.0362\n",
            "[0/25][736/782] Loss_D: 0.4425 Loss_G: 2.7919\n",
            "[0/25][737/782] Loss_D: 0.5073 Loss_G: 3.5742\n",
            "[0/25][738/782] Loss_D: 0.4350 Loss_G: 2.7740\n",
            "[0/25][739/782] Loss_D: 0.6155 Loss_G: 3.4228\n",
            "[0/25][740/782] Loss_D: 0.4306 Loss_G: 2.5707\n",
            "[0/25][741/782] Loss_D: 0.4610 Loss_G: 4.2425\n",
            "[0/25][742/782] Loss_D: 0.8444 Loss_G: 1.6639\n",
            "[0/25][743/782] Loss_D: 0.9081 Loss_G: 6.0228\n",
            "[0/25][744/782] Loss_D: 1.1475 Loss_G: 2.3467\n",
            "[0/25][745/782] Loss_D: 0.3688 Loss_G: 1.9917\n",
            "[0/25][746/782] Loss_D: 0.7157 Loss_G: 5.7807\n",
            "[0/25][747/782] Loss_D: 0.7785 Loss_G: 1.9681\n",
            "[0/25][748/782] Loss_D: 0.6586 Loss_G: 5.2449\n",
            "[0/25][749/782] Loss_D: 0.6076 Loss_G: 2.6973\n",
            "[0/25][750/782] Loss_D: 1.0574 Loss_G: 2.7202\n",
            "[0/25][751/782] Loss_D: 0.6918 Loss_G: 4.6989\n",
            "[0/25][752/782] Loss_D: 0.6551 Loss_G: 2.5739\n",
            "[0/25][753/782] Loss_D: 0.7196 Loss_G: 3.0060\n",
            "[0/25][754/782] Loss_D: 0.5254 Loss_G: 3.8403\n",
            "[0/25][755/782] Loss_D: 0.6021 Loss_G: 2.3175\n",
            "[0/25][756/782] Loss_D: 0.2970 Loss_G: 3.8616\n",
            "[0/25][757/782] Loss_D: 0.3575 Loss_G: 4.9584\n",
            "[0/25][758/782] Loss_D: 0.6196 Loss_G: 2.4918\n",
            "[0/25][759/782] Loss_D: 0.5311 Loss_G: 5.0591\n",
            "[0/25][760/782] Loss_D: 0.4506 Loss_G: 3.2757\n",
            "[0/25][761/782] Loss_D: 0.3149 Loss_G: 5.3341\n",
            "[0/25][762/782] Loss_D: 0.1924 Loss_G: 4.4892\n",
            "[0/25][763/782] Loss_D: 0.1953 Loss_G: 3.5056\n",
            "[0/25][764/782] Loss_D: 0.3213 Loss_G: 4.6917\n",
            "[0/25][765/782] Loss_D: 0.3016 Loss_G: 3.4289\n",
            "[0/25][766/782] Loss_D: 0.3507 Loss_G: 4.5497\n",
            "[0/25][767/782] Loss_D: 0.5652 Loss_G: 3.2039\n",
            "[0/25][768/782] Loss_D: 0.6089 Loss_G: 4.4895\n",
            "[0/25][769/782] Loss_D: 0.2895 Loss_G: 4.2880\n",
            "[0/25][770/782] Loss_D: 0.2029 Loss_G: 4.3933\n",
            "[0/25][771/782] Loss_D: 0.1862 Loss_G: 5.2330\n",
            "[0/25][772/782] Loss_D: 0.1905 Loss_G: 4.6105\n",
            "[0/25][773/782] Loss_D: 0.1575 Loss_G: 4.4328\n",
            "[0/25][774/782] Loss_D: 0.2363 Loss_G: 5.2574\n",
            "[0/25][775/782] Loss_D: 0.2487 Loss_G: 4.0434\n",
            "[0/25][776/782] Loss_D: 0.3315 Loss_G: 4.0790\n",
            "[0/25][777/782] Loss_D: 0.1963 Loss_G: 4.0424\n",
            "[0/25][778/782] Loss_D: 0.2007 Loss_G: 4.2295\n",
            "[0/25][779/782] Loss_D: 0.3757 Loss_G: 6.8442\n",
            "[0/25][780/782] Loss_D: 0.4797 Loss_G: 4.1467\n",
            "[0/25][781/782] Loss_D: 0.2306 Loss_G: 5.6984\n",
            "[1/25][0/782] Loss_D: 0.2130 Loss_G: 6.5871\n",
            "[1/25][1/782] Loss_D: 0.2634 Loss_G: 4.3813\n",
            "[1/25][2/782] Loss_D: 0.2206 Loss_G: 5.0268\n",
            "[1/25][3/782] Loss_D: 0.2623 Loss_G: 4.9825\n",
            "[1/25][4/782] Loss_D: 0.6412 Loss_G: 2.9318\n",
            "[1/25][5/782] Loss_D: 0.5477 Loss_G: 5.7793\n",
            "[1/25][6/782] Loss_D: 0.6260 Loss_G: 8.8863\n",
            "[1/25][7/782] Loss_D: 0.6646 Loss_G: 3.1780\n",
            "[1/25][8/782] Loss_D: 0.6144 Loss_G: 4.6312\n",
            "[1/25][9/782] Loss_D: 0.4319 Loss_G: 6.5784\n",
            "[1/25][10/782] Loss_D: 0.9030 Loss_G: 0.1117\n",
            "[1/25][11/782] Loss_D: 3.5883 Loss_G: 10.1028\n",
            "[1/25][12/782] Loss_D: 1.5084 Loss_G: 0.3405\n",
            "[1/25][13/782] Loss_D: 4.3737 Loss_G: 8.9204\n",
            "[1/25][14/782] Loss_D: 4.3833 Loss_G: 3.3234\n",
            "[1/25][15/782] Loss_D: 2.7123 Loss_G: 0.4510\n",
            "[1/25][16/782] Loss_D: 3.2366 Loss_G: 3.6507\n",
            "[1/25][17/782] Loss_D: 1.5568 Loss_G: 4.2660\n",
            "[1/25][18/782] Loss_D: 1.4961 Loss_G: 2.2238\n",
            "[1/25][19/782] Loss_D: 0.9704 Loss_G: 2.1052\n",
            "[1/25][20/782] Loss_D: 1.2085 Loss_G: 2.3559\n",
            "[1/25][21/782] Loss_D: 0.7360 Loss_G: 4.0491\n",
            "[1/25][22/782] Loss_D: 0.6817 Loss_G: 2.8709\n",
            "[1/25][23/782] Loss_D: 0.7880 Loss_G: 2.0228\n",
            "[1/25][24/782] Loss_D: 1.3948 Loss_G: 3.7954\n",
            "[1/25][25/782] Loss_D: 1.1482 Loss_G: 2.8894\n",
            "[1/25][26/782] Loss_D: 1.7517 Loss_G: 1.0762\n",
            "[1/25][27/782] Loss_D: 2.1300 Loss_G: 2.3608\n",
            "[1/25][28/782] Loss_D: 1.8810 Loss_G: 1.8711\n",
            "[1/25][29/782] Loss_D: 1.1521 Loss_G: 2.1978\n",
            "[1/25][30/782] Loss_D: 1.2785 Loss_G: 2.0649\n",
            "[1/25][31/782] Loss_D: 1.2587 Loss_G: 2.2385\n",
            "[1/25][32/782] Loss_D: 1.0607 Loss_G: 2.5289\n",
            "[1/25][33/782] Loss_D: 1.0936 Loss_G: 2.3983\n",
            "[1/25][34/782] Loss_D: 0.9033 Loss_G: 2.1434\n",
            "[1/25][35/782] Loss_D: 0.8683 Loss_G: 2.9282\n",
            "[1/25][36/782] Loss_D: 0.6626 Loss_G: 2.8913\n",
            "[1/25][37/782] Loss_D: 0.7411 Loss_G: 2.8251\n",
            "[1/25][38/782] Loss_D: 0.7709 Loss_G: 3.0032\n",
            "[1/25][39/782] Loss_D: 0.8645 Loss_G: 2.9425\n",
            "[1/25][40/782] Loss_D: 0.9304 Loss_G: 2.4711\n",
            "[1/25][41/782] Loss_D: 1.0716 Loss_G: 3.2095\n",
            "[1/25][42/782] Loss_D: 0.8424 Loss_G: 3.5435\n",
            "[1/25][43/782] Loss_D: 1.1598 Loss_G: 1.7364\n",
            "[1/25][44/782] Loss_D: 1.3054 Loss_G: 4.2635\n",
            "[1/25][45/782] Loss_D: 0.7784 Loss_G: 3.0773\n",
            "[1/25][46/782] Loss_D: 0.5260 Loss_G: 2.6574\n",
            "[1/25][47/782] Loss_D: 0.8208 Loss_G: 3.8599\n",
            "[1/25][48/782] Loss_D: 0.7381 Loss_G: 2.4165\n",
            "[1/25][49/782] Loss_D: 1.1286 Loss_G: 3.6587\n",
            "[1/25][50/782] Loss_D: 0.8756 Loss_G: 2.5461\n",
            "[1/25][51/782] Loss_D: 0.9123 Loss_G: 2.8181\n",
            "[1/25][52/782] Loss_D: 0.8215 Loss_G: 3.8991\n",
            "[1/25][53/782] Loss_D: 1.0651 Loss_G: 2.2284\n",
            "[1/25][54/782] Loss_D: 1.0126 Loss_G: 2.9307\n",
            "[1/25][55/782] Loss_D: 1.0101 Loss_G: 2.5018\n",
            "[1/25][56/782] Loss_D: 0.6404 Loss_G: 2.1824\n",
            "[1/25][57/782] Loss_D: 0.7877 Loss_G: 3.6683\n",
            "[1/25][58/782] Loss_D: 0.8836 Loss_G: 2.6045\n",
            "[1/25][59/782] Loss_D: 1.3288 Loss_G: 2.8752\n",
            "[1/25][60/782] Loss_D: 1.1077 Loss_G: 3.5493\n",
            "[1/25][61/782] Loss_D: 1.2317 Loss_G: 1.2496\n",
            "[1/25][62/782] Loss_D: 1.3273 Loss_G: 4.7910\n",
            "[1/25][63/782] Loss_D: 1.1284 Loss_G: 2.6480\n",
            "[1/25][64/782] Loss_D: 0.5466 Loss_G: 2.1013\n",
            "[1/25][65/782] Loss_D: 0.8327 Loss_G: 4.5636\n",
            "[1/25][66/782] Loss_D: 0.4228 Loss_G: 3.9579\n",
            "[1/25][67/782] Loss_D: 0.5024 Loss_G: 2.5038\n",
            "[1/25][68/782] Loss_D: 0.9249 Loss_G: 4.4032\n",
            "[1/25][69/782] Loss_D: 0.8230 Loss_G: 2.3736\n",
            "[1/25][70/782] Loss_D: 1.1546 Loss_G: 3.6681\n",
            "[1/25][71/782] Loss_D: 1.1468 Loss_G: 1.5231\n",
            "[1/25][72/782] Loss_D: 1.2275 Loss_G: 4.9807\n",
            "[1/25][73/782] Loss_D: 1.3257 Loss_G: 2.2156\n",
            "[1/25][74/782] Loss_D: 0.8085 Loss_G: 3.4362\n",
            "[1/25][75/782] Loss_D: 0.6567 Loss_G: 2.8856\n",
            "[1/25][76/782] Loss_D: 0.6256 Loss_G: 2.4685\n",
            "[1/25][77/782] Loss_D: 0.7017 Loss_G: 3.3861\n",
            "[1/25][78/782] Loss_D: 0.4702 Loss_G: 4.2638\n",
            "[1/25][79/782] Loss_D: 0.8121 Loss_G: 1.9940\n",
            "[1/25][80/782] Loss_D: 0.8539 Loss_G: 3.8639\n",
            "[1/25][81/782] Loss_D: 0.6478 Loss_G: 2.7639\n",
            "[1/25][82/782] Loss_D: 0.5154 Loss_G: 3.0961\n",
            "[1/25][83/782] Loss_D: 0.5146 Loss_G: 3.2172\n",
            "[1/25][84/782] Loss_D: 0.4806 Loss_G: 2.9536\n",
            "[1/25][85/782] Loss_D: 0.7874 Loss_G: 2.7012\n",
            "[1/25][86/782] Loss_D: 0.8158 Loss_G: 2.9167\n",
            "[1/25][87/782] Loss_D: 0.6211 Loss_G: 3.6574\n",
            "[1/25][88/782] Loss_D: 0.4160 Loss_G: 3.1234\n",
            "[1/25][89/782] Loss_D: 0.7259 Loss_G: 2.0746\n",
            "[1/25][90/782] Loss_D: 0.8715 Loss_G: 5.1183\n",
            "[1/25][91/782] Loss_D: 0.7053 Loss_G: 3.1058\n",
            "[1/25][92/782] Loss_D: 0.7037 Loss_G: 1.7767\n",
            "[1/25][93/782] Loss_D: 1.0369 Loss_G: 6.0077\n",
            "[1/25][94/782] Loss_D: 0.9391 Loss_G: 4.0279\n",
            "[1/25][95/782] Loss_D: 0.4526 Loss_G: 2.8562\n",
            "[1/25][96/782] Loss_D: 0.8296 Loss_G: 4.3650\n",
            "[1/25][97/782] Loss_D: 0.5118 Loss_G: 4.5311\n",
            "[1/25][98/782] Loss_D: 0.8353 Loss_G: 2.2918\n",
            "[1/25][99/782] Loss_D: 1.0105 Loss_G: 5.0158\n",
            "[1/25][100/782] Loss_D: 0.6467 Loss_G: 4.0040\n",
            "[1/25][101/782] Loss_D: 0.4697 Loss_G: 2.6382\n",
            "[1/25][102/782] Loss_D: 0.7066 Loss_G: 5.2754\n",
            "[1/25][103/782] Loss_D: 0.4611 Loss_G: 4.1966\n",
            "[1/25][104/782] Loss_D: 0.3163 Loss_G: 3.0785\n",
            "[1/25][105/782] Loss_D: 0.5724 Loss_G: 5.1964\n",
            "[1/25][106/782] Loss_D: 0.3199 Loss_G: 4.5848\n",
            "[1/25][107/782] Loss_D: 0.3404 Loss_G: 3.6343\n",
            "[1/25][108/782] Loss_D: 0.3442 Loss_G: 3.6779\n",
            "[1/25][109/782] Loss_D: 0.5987 Loss_G: 4.1743\n",
            "[1/25][110/782] Loss_D: 0.4575 Loss_G: 3.7683\n",
            "[1/25][111/782] Loss_D: 0.7114 Loss_G: 4.0306\n",
            "[1/25][112/782] Loss_D: 0.8278 Loss_G: 3.1777\n",
            "[1/25][113/782] Loss_D: 0.8741 Loss_G: 4.9966\n",
            "[1/25][114/782] Loss_D: 1.1191 Loss_G: 1.9933\n",
            "[1/25][115/782] Loss_D: 1.0928 Loss_G: 5.7512\n",
            "[1/25][116/782] Loss_D: 1.5377 Loss_G: 2.2391\n",
            "[1/25][117/782] Loss_D: 0.6873 Loss_G: 4.1508\n",
            "[1/25][118/782] Loss_D: 0.3853 Loss_G: 5.0207\n",
            "[1/25][119/782] Loss_D: 0.5848 Loss_G: 2.5629\n",
            "[1/25][120/782] Loss_D: 0.5395 Loss_G: 3.8704\n",
            "[1/25][121/782] Loss_D: 0.5851 Loss_G: 4.3492\n",
            "[1/25][122/782] Loss_D: 0.3896 Loss_G: 3.4817\n",
            "[1/25][123/782] Loss_D: 0.3881 Loss_G: 3.6103\n",
            "[1/25][124/782] Loss_D: 0.3532 Loss_G: 4.2729\n",
            "[1/25][125/782] Loss_D: 0.3090 Loss_G: 3.6486\n",
            "[1/25][126/782] Loss_D: 0.2857 Loss_G: 4.3834\n",
            "[1/25][127/782] Loss_D: 0.2727 Loss_G: 3.8780\n",
            "[1/25][128/782] Loss_D: 0.3570 Loss_G: 3.0588\n",
            "[1/25][129/782] Loss_D: 0.4507 Loss_G: 4.3090\n",
            "[1/25][130/782] Loss_D: 0.3395 Loss_G: 4.4661\n",
            "[1/25][131/782] Loss_D: 0.3082 Loss_G: 3.6420\n",
            "[1/25][132/782] Loss_D: 0.4633 Loss_G: 4.3520\n",
            "[1/25][133/782] Loss_D: 0.4547 Loss_G: 5.6218\n",
            "[1/25][134/782] Loss_D: 0.8882 Loss_G: 1.3336\n",
            "[1/25][135/782] Loss_D: 1.6909 Loss_G: 11.0240\n",
            "[1/25][136/782] Loss_D: 3.7244 Loss_G: 4.5503\n",
            "[1/25][137/782] Loss_D: 0.2957 Loss_G: 2.4795\n",
            "[1/25][138/782] Loss_D: 0.7418 Loss_G: 5.6942\n",
            "[1/25][139/782] Loss_D: 0.3305 Loss_G: 4.0045\n",
            "[1/25][140/782] Loss_D: 0.4518 Loss_G: 2.4848\n",
            "[1/25][141/782] Loss_D: 0.5713 Loss_G: 5.3221\n",
            "[1/25][142/782] Loss_D: 0.4964 Loss_G: 2.7804\n",
            "[1/25][143/782] Loss_D: 0.7471 Loss_G: 1.9142\n",
            "[1/25][144/782] Loss_D: 0.8250 Loss_G: 5.8236\n",
            "[1/25][145/782] Loss_D: 0.6464 Loss_G: 3.4459\n",
            "[1/25][146/782] Loss_D: 0.3691 Loss_G: 3.8259\n",
            "[1/25][147/782] Loss_D: 0.6398 Loss_G: 3.2887\n",
            "[1/25][148/782] Loss_D: 0.7326 Loss_G: 2.9926\n",
            "[1/25][149/782] Loss_D: 0.5397 Loss_G: 4.2601\n",
            "[1/25][150/782] Loss_D: 0.7020 Loss_G: 2.7992\n",
            "[1/25][151/782] Loss_D: 0.5900 Loss_G: 3.2682\n",
            "[1/25][152/782] Loss_D: 0.4543 Loss_G: 4.2601\n",
            "[1/25][153/782] Loss_D: 0.4401 Loss_G: 2.9107\n",
            "[1/25][154/782] Loss_D: 0.4201 Loss_G: 3.8363\n",
            "[1/25][155/782] Loss_D: 0.3250 Loss_G: 3.2550\n",
            "[1/25][156/782] Loss_D: 0.1995 Loss_G: 3.4415\n",
            "[1/25][157/782] Loss_D: 0.2079 Loss_G: 3.8484\n",
            "[1/25][158/782] Loss_D: 0.3006 Loss_G: 4.3167\n",
            "[1/25][159/782] Loss_D: 0.2931 Loss_G: 3.2980\n",
            "[1/25][160/782] Loss_D: 0.4103 Loss_G: 2.7868\n",
            "[1/25][161/782] Loss_D: 0.3070 Loss_G: 4.4735\n",
            "[1/25][162/782] Loss_D: 0.4013 Loss_G: 3.3474\n",
            "[1/25][163/782] Loss_D: 0.3897 Loss_G: 2.9137\n",
            "[1/25][164/782] Loss_D: 0.5269 Loss_G: 5.9338\n",
            "[1/25][165/782] Loss_D: 0.4347 Loss_G: 4.4271\n",
            "[1/25][166/782] Loss_D: 0.3122 Loss_G: 2.6490\n",
            "[1/25][167/782] Loss_D: 0.4269 Loss_G: 4.6869\n",
            "[1/25][168/782] Loss_D: 0.3199 Loss_G: 5.0986\n",
            "[1/25][169/782] Loss_D: 0.4405 Loss_G: 2.6353\n",
            "[1/25][170/782] Loss_D: 0.6289 Loss_G: 5.4027\n",
            "[1/25][171/782] Loss_D: 0.5363 Loss_G: 2.6459\n",
            "[1/25][172/782] Loss_D: 0.5478 Loss_G: 4.7217\n",
            "[1/25][173/782] Loss_D: 0.2804 Loss_G: 3.5692\n",
            "[1/25][174/782] Loss_D: 0.4411 Loss_G: 3.1766\n",
            "[1/25][175/782] Loss_D: 0.3243 Loss_G: 4.3036\n",
            "[1/25][176/782] Loss_D: 0.5429 Loss_G: 2.0489\n",
            "[1/25][177/782] Loss_D: 0.6618 Loss_G: 5.1509\n",
            "[1/25][178/782] Loss_D: 0.6023 Loss_G: 2.8933\n",
            "[1/25][179/782] Loss_D: 0.4958 Loss_G: 3.0919\n",
            "[1/25][180/782] Loss_D: 0.4244 Loss_G: 4.0989\n",
            "[1/25][181/782] Loss_D: 0.2990 Loss_G: 3.6758\n",
            "[1/25][182/782] Loss_D: 0.1653 Loss_G: 3.7453\n",
            "[1/25][183/782] Loss_D: 0.3673 Loss_G: 3.3320\n",
            "[1/25][184/782] Loss_D: 0.2465 Loss_G: 5.1217\n",
            "[1/25][185/782] Loss_D: 0.3037 Loss_G: 3.8212\n",
            "[1/25][186/782] Loss_D: 0.2309 Loss_G: 3.6003\n",
            "[1/25][187/782] Loss_D: 0.3164 Loss_G: 5.6846\n",
            "[1/25][188/782] Loss_D: 0.4592 Loss_G: 2.9221\n",
            "[1/25][189/782] Loss_D: 0.3792 Loss_G: 5.6286\n",
            "[1/25][190/782] Loss_D: 0.2328 Loss_G: 4.6367\n",
            "[1/25][191/782] Loss_D: 0.1748 Loss_G: 4.1012\n",
            "[1/25][192/782] Loss_D: 0.3446 Loss_G: 4.7498\n",
            "[1/25][193/782] Loss_D: 0.3871 Loss_G: 3.4954\n",
            "[1/25][194/782] Loss_D: 0.3257 Loss_G: 4.1547\n",
            "[1/25][195/782] Loss_D: 0.3430 Loss_G: 2.9057\n",
            "[1/25][196/782] Loss_D: 0.5605 Loss_G: 6.2041\n",
            "[1/25][197/782] Loss_D: 0.4899 Loss_G: 3.8918\n",
            "[1/25][198/782] Loss_D: 0.2446 Loss_G: 2.5712\n",
            "[1/25][199/782] Loss_D: 0.5758 Loss_G: 6.9673\n",
            "[1/25][200/782] Loss_D: 0.8910 Loss_G: 3.5696\n",
            "[1/25][201/782] Loss_D: 0.2109 Loss_G: 2.6560\n",
            "[1/25][202/782] Loss_D: 0.5670 Loss_G: 6.1537\n",
            "[1/25][203/782] Loss_D: 1.1274 Loss_G: 1.1285\n",
            "[1/25][204/782] Loss_D: 1.1375 Loss_G: 6.0340\n",
            "[1/25][205/782] Loss_D: 0.9489 Loss_G: 2.1485\n",
            "[1/25][206/782] Loss_D: 0.7863 Loss_G: 3.2036\n",
            "[1/25][207/782] Loss_D: 0.6771 Loss_G: 3.8070\n",
            "[1/25][208/782] Loss_D: 0.4773 Loss_G: 2.9326\n",
            "[1/25][209/782] Loss_D: 0.4914 Loss_G: 2.7799\n",
            "[1/25][210/782] Loss_D: 0.7132 Loss_G: 5.0857\n",
            "[1/25][211/782] Loss_D: 1.6523 Loss_G: 0.3941\n",
            "[1/25][212/782] Loss_D: 2.5120 Loss_G: 6.3418\n",
            "[1/25][213/782] Loss_D: 1.7184 Loss_G: 2.7014\n",
            "[1/25][214/782] Loss_D: 0.7138 Loss_G: 2.8854\n",
            "[1/25][215/782] Loss_D: 0.3770 Loss_G: 3.7251\n",
            "[1/25][216/782] Loss_D: 0.3338 Loss_G: 3.4968\n",
            "[1/25][217/782] Loss_D: 0.2507 Loss_G: 3.4473\n",
            "[1/25][218/782] Loss_D: 0.2508 Loss_G: 3.4261\n",
            "[1/25][219/782] Loss_D: 0.4684 Loss_G: 4.0548\n",
            "[1/25][220/782] Loss_D: 0.5061 Loss_G: 2.7355\n",
            "[1/25][221/782] Loss_D: 0.4023 Loss_G: 2.3226\n",
            "[1/25][222/782] Loss_D: 0.8415 Loss_G: 3.9684\n",
            "[1/25][223/782] Loss_D: 0.6232 Loss_G: 2.3734\n",
            "[1/25][224/782] Loss_D: 0.3747 Loss_G: 4.4405\n",
            "[1/25][225/782] Loss_D: 0.2443 Loss_G: 3.8301\n",
            "[1/25][226/782] Loss_D: 0.2739 Loss_G: 3.2244\n",
            "[1/25][227/782] Loss_D: 0.5895 Loss_G: 5.3714\n",
            "[1/25][228/782] Loss_D: 1.0256 Loss_G: 1.4124\n",
            "[1/25][229/782] Loss_D: 1.3077 Loss_G: 6.6846\n",
            "[1/25][230/782] Loss_D: 1.2332 Loss_G: 2.7238\n",
            "[1/25][231/782] Loss_D: 0.5597 Loss_G: 3.5914\n",
            "[1/25][232/782] Loss_D: 0.4854 Loss_G: 3.8861\n",
            "[1/25][233/782] Loss_D: 0.3947 Loss_G: 3.5893\n",
            "[1/25][234/782] Loss_D: 0.7559 Loss_G: 2.4256\n",
            "[1/25][235/782] Loss_D: 1.2657 Loss_G: 4.2223\n",
            "[1/25][236/782] Loss_D: 1.3521 Loss_G: 1.6348\n",
            "[1/25][237/782] Loss_D: 1.4050 Loss_G: 4.6445\n",
            "[1/25][238/782] Loss_D: 1.1027 Loss_G: 2.7434\n",
            "[1/25][239/782] Loss_D: 0.4168 Loss_G: 2.5295\n",
            "[1/25][240/782] Loss_D: 0.7117 Loss_G: 4.8611\n",
            "[1/25][241/782] Loss_D: 0.3788 Loss_G: 4.2599\n",
            "[1/25][242/782] Loss_D: 0.2083 Loss_G: 3.4926\n",
            "[1/25][243/782] Loss_D: 0.5154 Loss_G: 4.7605\n",
            "[1/25][244/782] Loss_D: 0.5480 Loss_G: 3.1983\n",
            "[1/25][245/782] Loss_D: 0.3836 Loss_G: 4.0308\n",
            "[1/25][246/782] Loss_D: 0.3756 Loss_G: 3.9780\n",
            "[1/25][247/782] Loss_D: 0.3446 Loss_G: 3.9716\n",
            "[1/25][248/782] Loss_D: 0.4882 Loss_G: 5.1708\n",
            "[1/25][249/782] Loss_D: 0.8912 Loss_G: 2.0090\n",
            "[1/25][250/782] Loss_D: 1.5505 Loss_G: 8.0961\n",
            "[1/25][251/782] Loss_D: 1.2863 Loss_G: 3.1646\n",
            "[1/25][252/782] Loss_D: 0.8194 Loss_G: 5.2371\n",
            "[1/25][253/782] Loss_D: 0.4498 Loss_G: 4.7503\n",
            "[1/25][254/782] Loss_D: 0.5339 Loss_G: 3.7715\n",
            "[1/25][255/782] Loss_D: 0.6281 Loss_G: 4.8802\n",
            "[1/25][256/782] Loss_D: 0.8983 Loss_G: 1.7331\n",
            "[1/25][257/782] Loss_D: 1.0251 Loss_G: 5.9080\n",
            "[1/25][258/782] Loss_D: 0.8854 Loss_G: 2.3577\n",
            "[1/25][259/782] Loss_D: 0.8446 Loss_G: 3.9715\n",
            "[1/25][260/782] Loss_D: 0.7786 Loss_G: 3.7402\n",
            "[1/25][261/782] Loss_D: 0.9219 Loss_G: 1.9350\n",
            "[1/25][262/782] Loss_D: 1.2572 Loss_G: 5.7700\n",
            "[1/25][263/782] Loss_D: 1.4005 Loss_G: 1.8889\n",
            "[1/25][264/782] Loss_D: 1.1245 Loss_G: 4.7024\n",
            "[1/25][265/782] Loss_D: 0.7039 Loss_G: 2.9969\n",
            "[1/25][266/782] Loss_D: 1.0301 Loss_G: 4.7669\n",
            "[1/25][267/782] Loss_D: 0.7541 Loss_G: 3.3030\n",
            "[1/25][268/782] Loss_D: 0.5807 Loss_G: 3.2748\n",
            "[1/25][269/782] Loss_D: 0.4382 Loss_G: 4.0722\n",
            "[1/25][270/782] Loss_D: 0.6134 Loss_G: 3.2975\n",
            "[1/25][271/782] Loss_D: 0.5750 Loss_G: 3.2441\n",
            "[1/25][272/782] Loss_D: 0.4500 Loss_G: 4.3607\n",
            "[1/25][273/782] Loss_D: 0.4438 Loss_G: 3.9497\n",
            "[1/25][274/782] Loss_D: 0.3987 Loss_G: 3.3557\n",
            "[1/25][275/782] Loss_D: 0.4134 Loss_G: 4.5721\n",
            "[1/25][276/782] Loss_D: 0.3193 Loss_G: 4.0335\n",
            "[1/25][277/782] Loss_D: 0.5732 Loss_G: 2.8082\n",
            "[1/25][278/782] Loss_D: 0.6635 Loss_G: 3.8183\n",
            "[1/25][279/782] Loss_D: 0.4795 Loss_G: 4.0116\n",
            "[1/25][280/782] Loss_D: 0.4358 Loss_G: 3.3747\n",
            "[1/25][281/782] Loss_D: 0.7670 Loss_G: 3.5879\n",
            "[1/25][282/782] Loss_D: 0.4967 Loss_G: 3.0157\n",
            "[1/25][283/782] Loss_D: 0.6015 Loss_G: 5.7006\n",
            "[1/25][284/782] Loss_D: 0.3489 Loss_G: 3.9898\n",
            "[1/25][285/782] Loss_D: 0.5427 Loss_G: 4.6178\n",
            "[1/25][286/782] Loss_D: 0.4213 Loss_G: 3.4956\n",
            "[1/25][287/782] Loss_D: 0.2937 Loss_G: 4.1874\n",
            "[1/25][288/782] Loss_D: 0.3135 Loss_G: 3.9453\n",
            "[1/25][289/782] Loss_D: 0.3117 Loss_G: 4.0509\n",
            "[1/25][290/782] Loss_D: 0.2128 Loss_G: 3.6075\n",
            "[1/25][291/782] Loss_D: 0.2461 Loss_G: 4.4257\n",
            "[1/25][292/782] Loss_D: 0.3229 Loss_G: 3.7851\n",
            "[1/25][293/782] Loss_D: 0.3861 Loss_G: 2.7462\n",
            "[1/25][294/782] Loss_D: 0.8452 Loss_G: 6.1034\n",
            "[1/25][295/782] Loss_D: 1.5290 Loss_G: 1.9809\n",
            "[1/25][296/782] Loss_D: 0.6551 Loss_G: 4.6447\n",
            "[1/25][297/782] Loss_D: 0.3766 Loss_G: 3.9282\n",
            "[1/25][298/782] Loss_D: 0.3806 Loss_G: 3.4485\n",
            "[1/25][299/782] Loss_D: 0.6444 Loss_G: 3.5781\n",
            "[1/25][300/782] Loss_D: 0.5889 Loss_G: 3.5616\n",
            "[1/25][301/782] Loss_D: 0.5582 Loss_G: 3.2316\n",
            "[1/25][302/782] Loss_D: 0.5218 Loss_G: 3.3823\n",
            "[1/25][303/782] Loss_D: 0.3779 Loss_G: 4.9810\n",
            "[1/25][304/782] Loss_D: 0.3535 Loss_G: 3.7417\n",
            "[1/25][305/782] Loss_D: 0.2958 Loss_G: 3.2666\n",
            "[1/25][306/782] Loss_D: 0.3302 Loss_G: 4.7262\n",
            "[1/25][307/782] Loss_D: 0.2471 Loss_G: 4.3454\n",
            "[1/25][308/782] Loss_D: 0.2614 Loss_G: 3.3491\n",
            "[1/25][309/782] Loss_D: 0.4457 Loss_G: 5.1032\n",
            "[1/25][310/782] Loss_D: 0.2956 Loss_G: 4.3569\n",
            "[1/25][311/782] Loss_D: 0.2049 Loss_G: 4.1289\n",
            "[1/25][312/782] Loss_D: 0.3949 Loss_G: 3.6423\n",
            "[1/25][313/782] Loss_D: 0.2994 Loss_G: 4.7023\n",
            "[1/25][314/782] Loss_D: 0.3201 Loss_G: 3.5871\n",
            "[1/25][315/782] Loss_D: 0.5946 Loss_G: 5.2176\n",
            "[1/25][316/782] Loss_D: 0.7093 Loss_G: 2.6713\n",
            "[1/25][317/782] Loss_D: 0.6614 Loss_G: 5.2850\n",
            "[1/25][318/782] Loss_D: 0.8994 Loss_G: 1.9065\n",
            "[1/25][319/782] Loss_D: 1.0530 Loss_G: 7.0893\n",
            "[1/25][320/782] Loss_D: 0.9814 Loss_G: 3.7073\n",
            "[1/25][321/782] Loss_D: 0.3565 Loss_G: 4.1679\n",
            "[1/25][322/782] Loss_D: 0.2686 Loss_G: 4.8042\n",
            "[1/25][323/782] Loss_D: 0.2320 Loss_G: 4.5787\n",
            "[1/25][324/782] Loss_D: 0.7254 Loss_G: 2.6267\n",
            "[1/25][325/782] Loss_D: 0.8585 Loss_G: 4.0163\n",
            "[1/25][326/782] Loss_D: 0.6645 Loss_G: 3.1983\n",
            "[1/25][327/782] Loss_D: 0.6260 Loss_G: 5.5593\n",
            "[1/25][328/782] Loss_D: 0.6697 Loss_G: 2.4424\n",
            "[1/25][329/782] Loss_D: 1.1076 Loss_G: 7.7181\n",
            "[1/25][330/782] Loss_D: 1.1633 Loss_G: 3.1824\n",
            "[1/25][331/782] Loss_D: 0.9860 Loss_G: 4.4858\n",
            "[1/25][332/782] Loss_D: 0.4327 Loss_G: 4.8074\n",
            "[1/25][333/782] Loss_D: 0.2956 Loss_G: 4.1273\n",
            "[1/25][334/782] Loss_D: 0.4048 Loss_G: 3.7026\n",
            "[1/25][335/782] Loss_D: 0.4755 Loss_G: 4.7918\n",
            "[1/25][336/782] Loss_D: 0.7747 Loss_G: 2.5687\n",
            "[1/25][337/782] Loss_D: 1.0198 Loss_G: 8.6611\n",
            "[1/25][338/782] Loss_D: 1.1547 Loss_G: 3.5578\n",
            "[1/25][339/782] Loss_D: 0.7013 Loss_G: 5.4696\n",
            "[1/25][340/782] Loss_D: 0.3913 Loss_G: 4.2371\n",
            "[1/25][341/782] Loss_D: 0.7720 Loss_G: 3.9400\n",
            "[1/25][342/782] Loss_D: 0.6579 Loss_G: 4.0134\n",
            "[1/25][343/782] Loss_D: 0.8268 Loss_G: 2.8420\n",
            "[1/25][344/782] Loss_D: 0.4783 Loss_G: 5.6387\n",
            "[1/25][345/782] Loss_D: 1.0617 Loss_G: 1.3718\n",
            "[1/25][346/782] Loss_D: 0.7188 Loss_G: 5.3621\n",
            "[1/25][347/782] Loss_D: 0.2261 Loss_G: 4.8779\n",
            "[1/25][348/782] Loss_D: 0.5408 Loss_G: 2.4712\n",
            "[1/25][349/782] Loss_D: 0.4725 Loss_G: 4.2427\n",
            "[1/25][350/782] Loss_D: 0.5362 Loss_G: 3.5503\n",
            "[1/25][351/782] Loss_D: 0.4145 Loss_G: 4.0080\n",
            "[1/25][352/782] Loss_D: 0.3111 Loss_G: 3.0271\n",
            "[1/25][353/782] Loss_D: 0.4588 Loss_G: 3.6575\n",
            "[1/25][354/782] Loss_D: 0.4410 Loss_G: 3.4544\n",
            "[1/25][355/782] Loss_D: 0.4247 Loss_G: 3.4525\n",
            "[1/25][356/782] Loss_D: 0.2661 Loss_G: 4.2163\n",
            "[1/25][357/782] Loss_D: 0.5137 Loss_G: 2.3399\n",
            "[1/25][358/782] Loss_D: 0.4291 Loss_G: 4.9843\n",
            "[1/25][359/782] Loss_D: 0.3615 Loss_G: 2.9615\n",
            "[1/25][360/782] Loss_D: 1.0891 Loss_G: 8.2591\n",
            "[1/25][361/782] Loss_D: 1.4795 Loss_G: 2.5305\n",
            "[1/25][362/782] Loss_D: 0.7314 Loss_G: 4.8271\n",
            "[1/25][363/782] Loss_D: 0.4373 Loss_G: 3.9961\n",
            "[1/25][364/782] Loss_D: 0.3767 Loss_G: 3.1536\n",
            "[1/25][365/782] Loss_D: 0.4962 Loss_G: 3.9655\n",
            "[1/25][366/782] Loss_D: 0.2881 Loss_G: 3.6901\n",
            "[1/25][367/782] Loss_D: 0.4244 Loss_G: 3.2738\n",
            "[1/25][368/782] Loss_D: 0.3107 Loss_G: 4.0096\n",
            "[1/25][369/782] Loss_D: 0.5352 Loss_G: 3.3317\n",
            "[1/25][370/782] Loss_D: 0.7036 Loss_G: 3.9352\n",
            "[1/25][371/782] Loss_D: 0.5681 Loss_G: 2.5699\n",
            "[1/25][372/782] Loss_D: 0.2907 Loss_G: 5.1382\n",
            "[1/25][373/782] Loss_D: 0.2298 Loss_G: 4.6595\n",
            "[1/25][374/782] Loss_D: 0.1880 Loss_G: 3.7897\n",
            "[1/25][375/782] Loss_D: 0.3693 Loss_G: 5.0744\n",
            "[1/25][376/782] Loss_D: 0.3161 Loss_G: 3.7549\n",
            "[1/25][377/782] Loss_D: 0.4629 Loss_G: 5.1989\n",
            "[1/25][378/782] Loss_D: 0.3786 Loss_G: 3.2897\n",
            "[1/25][379/782] Loss_D: 0.4845 Loss_G: 6.9676\n",
            "[1/25][380/782] Loss_D: 0.5853 Loss_G: 3.6384\n",
            "[1/25][381/782] Loss_D: 0.4093 Loss_G: 5.5315\n",
            "[1/25][382/782] Loss_D: 0.4570 Loss_G: 3.2294\n",
            "[1/25][383/782] Loss_D: 0.7306 Loss_G: 6.0556\n",
            "[1/25][384/782] Loss_D: 0.5782 Loss_G: 3.2126\n",
            "[1/25][385/782] Loss_D: 0.4985 Loss_G: 5.5105\n",
            "[1/25][386/782] Loss_D: 0.6258 Loss_G: 2.8286\n",
            "[1/25][387/782] Loss_D: 0.6258 Loss_G: 6.8024\n",
            "[1/25][388/782] Loss_D: 0.4442 Loss_G: 5.3156\n",
            "[1/25][389/782] Loss_D: 0.1618 Loss_G: 3.4250\n",
            "[1/25][390/782] Loss_D: 0.5794 Loss_G: 6.4034\n",
            "[1/25][391/782] Loss_D: 0.3438 Loss_G: 4.8516\n",
            "[1/25][392/782] Loss_D: 0.4008 Loss_G: 5.6855\n",
            "[1/25][393/782] Loss_D: 0.4480 Loss_G: 3.9419\n",
            "[1/25][394/782] Loss_D: 1.0190 Loss_G: 3.7509\n",
            "[1/25][395/782] Loss_D: 0.8034 Loss_G: 3.2634\n",
            "[1/25][396/782] Loss_D: 0.5727 Loss_G: 6.4188\n",
            "[1/25][397/782] Loss_D: 0.6694 Loss_G: 1.9716\n",
            "[1/25][398/782] Loss_D: 0.7930 Loss_G: 7.8065\n",
            "[1/25][399/782] Loss_D: 0.5884 Loss_G: 2.3164\n",
            "[1/25][400/782] Loss_D: 0.7888 Loss_G: 7.0094\n",
            "[1/25][401/782] Loss_D: 0.2147 Loss_G: 6.1537\n",
            "[1/25][402/782] Loss_D: 0.3441 Loss_G: 3.1050\n",
            "[1/25][403/782] Loss_D: 0.9420 Loss_G: 8.1180\n",
            "[1/25][404/782] Loss_D: 1.5065 Loss_G: 1.6688\n",
            "[1/25][405/782] Loss_D: 2.5074 Loss_G: 8.4985\n",
            "[1/25][406/782] Loss_D: 1.9801 Loss_G: 2.5638\n",
            "[1/25][407/782] Loss_D: 0.8896 Loss_G: 3.0934\n",
            "[1/25][408/782] Loss_D: 0.5367 Loss_G: 4.6573\n",
            "[1/25][409/782] Loss_D: 0.5158 Loss_G: 3.0934\n",
            "[1/25][410/782] Loss_D: 0.8172 Loss_G: 4.9486\n",
            "[1/25][411/782] Loss_D: 0.5193 Loss_G: 3.9500\n",
            "[1/25][412/782] Loss_D: 0.5701 Loss_G: 2.3198\n",
            "[1/25][413/782] Loss_D: 0.8496 Loss_G: 6.4577\n",
            "[1/25][414/782] Loss_D: 0.5170 Loss_G: 4.9894\n",
            "[1/25][415/782] Loss_D: 0.3549 Loss_G: 3.6127\n",
            "[1/25][416/782] Loss_D: 0.8118 Loss_G: 3.4014\n",
            "[1/25][417/782] Loss_D: 1.1516 Loss_G: 4.9019\n",
            "[1/25][418/782] Loss_D: 0.6436 Loss_G: 3.0673\n",
            "[1/25][419/782] Loss_D: 1.3348 Loss_G: 6.2802\n",
            "[1/25][420/782] Loss_D: 1.2136 Loss_G: 1.9562\n",
            "[1/25][421/782] Loss_D: 1.6290 Loss_G: 6.4584\n",
            "[1/25][422/782] Loss_D: 0.7255 Loss_G: 5.0576\n",
            "[1/25][423/782] Loss_D: 0.2544 Loss_G: 3.6238\n",
            "[1/25][424/782] Loss_D: 0.4944 Loss_G: 4.2716\n",
            "[1/25][425/782] Loss_D: 0.3845 Loss_G: 4.3007\n",
            "[1/25][426/782] Loss_D: 0.4568 Loss_G: 4.1210\n",
            "[1/25][427/782] Loss_D: 0.4783 Loss_G: 3.7262\n",
            "[1/25][428/782] Loss_D: 0.8724 Loss_G: 3.1492\n",
            "[1/25][429/782] Loss_D: 0.9874 Loss_G: 3.9184\n",
            "[1/25][430/782] Loss_D: 0.7847 Loss_G: 3.0864\n",
            "[1/25][431/782] Loss_D: 0.5919 Loss_G: 4.3981\n",
            "[1/25][432/782] Loss_D: 0.4237 Loss_G: 3.6780\n",
            "[1/25][433/782] Loss_D: 0.4358 Loss_G: 3.5850\n",
            "[1/25][434/782] Loss_D: 0.4236 Loss_G: 4.4557\n",
            "[1/25][435/782] Loss_D: 0.5142 Loss_G: 2.0144\n",
            "[1/25][436/782] Loss_D: 1.0368 Loss_G: 7.1946\n",
            "[1/25][437/782] Loss_D: 1.1285 Loss_G: 2.2835\n",
            "[1/25][438/782] Loss_D: 0.5754 Loss_G: 4.3901\n",
            "[1/25][439/782] Loss_D: 0.6377 Loss_G: 3.1374\n",
            "[1/25][440/782] Loss_D: 0.5999 Loss_G: 4.8086\n",
            "[1/25][441/782] Loss_D: 0.4402 Loss_G: 3.4114\n",
            "[1/25][442/782] Loss_D: 0.5546 Loss_G: 2.9121\n",
            "[1/25][443/782] Loss_D: 0.5239 Loss_G: 5.1698\n",
            "[1/25][444/782] Loss_D: 0.5495 Loss_G: 3.1628\n",
            "[1/25][445/782] Loss_D: 0.4180 Loss_G: 3.8742\n",
            "[1/25][446/782] Loss_D: 0.5311 Loss_G: 4.0982\n",
            "[1/25][447/782] Loss_D: 0.5232 Loss_G: 4.1340\n",
            "[1/25][448/782] Loss_D: 0.7356 Loss_G: 3.6543\n",
            "[1/25][449/782] Loss_D: 0.8172 Loss_G: 5.1037\n",
            "[1/25][450/782] Loss_D: 0.9657 Loss_G: 1.1660\n",
            "[1/25][451/782] Loss_D: 1.0452 Loss_G: 6.7725\n",
            "[1/25][452/782] Loss_D: 0.8447 Loss_G: 3.0314\n",
            "[1/25][453/782] Loss_D: 0.1634 Loss_G: 3.3737\n",
            "[1/25][454/782] Loss_D: 0.4346 Loss_G: 5.0824\n",
            "[1/25][455/782] Loss_D: 0.2563 Loss_G: 4.6982\n",
            "[1/25][456/782] Loss_D: 0.4753 Loss_G: 2.2410\n",
            "[1/25][457/782] Loss_D: 0.9824 Loss_G: 7.6489\n",
            "[1/25][458/782] Loss_D: 1.3958 Loss_G: 3.1886\n",
            "[1/25][459/782] Loss_D: 0.5215 Loss_G: 3.8772\n",
            "[1/25][460/782] Loss_D: 0.4757 Loss_G: 4.8921\n",
            "[1/25][461/782] Loss_D: 0.9470 Loss_G: 1.5612\n",
            "[1/25][462/782] Loss_D: 1.2388 Loss_G: 7.5510\n",
            "[1/25][463/782] Loss_D: 1.4687 Loss_G: 3.4094\n",
            "[1/25][464/782] Loss_D: 0.3032 Loss_G: 2.9092\n",
            "[1/25][465/782] Loss_D: 0.6041 Loss_G: 5.5158\n",
            "[1/25][466/782] Loss_D: 0.3740 Loss_G: 4.4010\n",
            "[1/25][467/782] Loss_D: 0.4603 Loss_G: 3.0175\n",
            "[1/25][468/782] Loss_D: 0.5657 Loss_G: 5.4264\n",
            "[1/25][469/782] Loss_D: 0.4954 Loss_G: 2.9974\n",
            "[1/25][470/782] Loss_D: 0.7076 Loss_G: 4.5482\n",
            "[1/25][471/782] Loss_D: 0.3205 Loss_G: 3.9460\n",
            "[1/25][472/782] Loss_D: 0.5109 Loss_G: 2.9588\n",
            "[1/25][473/782] Loss_D: 0.4656 Loss_G: 2.9307\n",
            "[1/25][474/782] Loss_D: 0.4720 Loss_G: 5.0017\n",
            "[1/25][475/782] Loss_D: 0.4595 Loss_G: 3.1619\n",
            "[1/25][476/782] Loss_D: 0.3521 Loss_G: 2.5368\n",
            "[1/25][477/782] Loss_D: 0.4863 Loss_G: 4.4310\n",
            "[1/25][478/782] Loss_D: 0.3468 Loss_G: 3.6279\n",
            "[1/25][479/782] Loss_D: 0.4121 Loss_G: 2.6345\n",
            "[1/25][480/782] Loss_D: 0.6304 Loss_G: 5.4123\n",
            "[1/25][481/782] Loss_D: 0.9146 Loss_G: 1.7446\n",
            "[1/25][482/782] Loss_D: 0.8663 Loss_G: 5.9672\n",
            "[1/25][483/782] Loss_D: 0.6378 Loss_G: 3.6532\n",
            "[1/25][484/782] Loss_D: 0.3499 Loss_G: 3.0757\n",
            "[1/25][485/782] Loss_D: 0.3760 Loss_G: 4.7359\n",
            "[1/25][486/782] Loss_D: 0.5143 Loss_G: 3.2159\n",
            "[1/25][487/782] Loss_D: 0.3193 Loss_G: 4.2881\n",
            "[1/25][488/782] Loss_D: 0.3015 Loss_G: 4.6933\n",
            "[1/25][489/782] Loss_D: 0.3068 Loss_G: 3.4757\n",
            "[1/25][490/782] Loss_D: 0.3389 Loss_G: 3.7748\n",
            "[1/25][491/782] Loss_D: 0.2923 Loss_G: 4.1614\n",
            "[1/25][492/782] Loss_D: 0.2276 Loss_G: 5.4831\n",
            "[1/25][493/782] Loss_D: 0.2391 Loss_G: 4.0090\n",
            "[1/25][494/782] Loss_D: 0.2321 Loss_G: 3.4183\n",
            "[1/25][495/782] Loss_D: 0.2814 Loss_G: 4.8347\n",
            "[1/25][496/782] Loss_D: 0.2299 Loss_G: 4.4006\n",
            "[1/25][497/782] Loss_D: 0.2917 Loss_G: 2.9751\n",
            "[1/25][498/782] Loss_D: 0.4068 Loss_G: 4.8331\n",
            "[1/25][499/782] Loss_D: 0.3207 Loss_G: 3.7644\n",
            "[1/25][500/782] Loss_D: 0.2663 Loss_G: 3.5946\n",
            "[1/25][501/782] Loss_D: 0.3211 Loss_G: 4.3252\n",
            "[1/25][502/782] Loss_D: 0.3087 Loss_G: 3.3318\n",
            "[1/25][503/782] Loss_D: 0.3901 Loss_G: 4.1005\n",
            "[1/25][504/782] Loss_D: 0.2396 Loss_G: 3.8434\n",
            "[1/25][505/782] Loss_D: 0.1674 Loss_G: 4.0143\n",
            "[1/25][506/782] Loss_D: 0.2654 Loss_G: 3.2256\n",
            "[1/25][507/782] Loss_D: 0.4059 Loss_G: 5.4579\n",
            "[1/25][508/782] Loss_D: 0.2672 Loss_G: 4.4947\n",
            "[1/25][509/782] Loss_D: 0.1419 Loss_G: 4.0179\n",
            "[1/25][510/782] Loss_D: 0.2245 Loss_G: 4.5177\n",
            "[1/25][511/782] Loss_D: 0.3927 Loss_G: 3.4766\n",
            "[1/25][512/782] Loss_D: 0.3535 Loss_G: 3.6227\n",
            "[1/25][513/782] Loss_D: 0.4321 Loss_G: 3.5778\n",
            "[1/25][514/782] Loss_D: 0.3065 Loss_G: 4.3144\n",
            "[1/25][515/782] Loss_D: 0.4629 Loss_G: 2.1329\n",
            "[1/25][516/782] Loss_D: 0.6005 Loss_G: 7.1707\n",
            "[1/25][517/782] Loss_D: 0.8278 Loss_G: 3.4883\n",
            "[1/25][518/782] Loss_D: 0.2299 Loss_G: 3.3036\n",
            "[1/25][519/782] Loss_D: 0.6270 Loss_G: 7.6881\n",
            "[1/25][520/782] Loss_D: 0.7974 Loss_G: 2.7190\n",
            "[1/25][521/782] Loss_D: 0.3751 Loss_G: 4.3379\n",
            "[1/25][522/782] Loss_D: 0.4633 Loss_G: 5.5006\n",
            "[1/25][523/782] Loss_D: 0.4790 Loss_G: 3.5375\n",
            "[1/25][524/782] Loss_D: 0.3962 Loss_G: 5.5173\n",
            "[1/25][525/782] Loss_D: 0.6814 Loss_G: 2.5275\n",
            "[1/25][526/782] Loss_D: 0.6134 Loss_G: 7.0834\n",
            "[1/25][527/782] Loss_D: 0.5411 Loss_G: 4.2836\n",
            "[1/25][528/782] Loss_D: 0.2609 Loss_G: 4.8214\n",
            "[1/25][529/782] Loss_D: 0.3466 Loss_G: 4.3762\n",
            "[1/25][530/782] Loss_D: 0.3525 Loss_G: 5.7103\n",
            "[1/25][531/782] Loss_D: 0.4020 Loss_G: 3.6898\n",
            "[1/25][532/782] Loss_D: 0.7116 Loss_G: 7.4662\n",
            "[1/25][533/782] Loss_D: 0.6651 Loss_G: 3.8967\n",
            "[1/25][534/782] Loss_D: 0.3813 Loss_G: 3.5079\n",
            "[1/25][535/782] Loss_D: 0.5764 Loss_G: 6.3681\n",
            "[1/25][536/782] Loss_D: 0.5199 Loss_G: 3.4840\n",
            "[1/25][537/782] Loss_D: 0.5963 Loss_G: 5.6662\n",
            "[1/25][538/782] Loss_D: 0.7173 Loss_G: 2.2862\n",
            "[1/25][539/782] Loss_D: 1.0299 Loss_G: 8.5405\n",
            "[1/25][540/782] Loss_D: 1.4787 Loss_G: 2.4246\n",
            "[1/25][541/782] Loss_D: 1.0610 Loss_G: 7.2005\n",
            "[1/25][542/782] Loss_D: 0.5558 Loss_G: 3.1739\n",
            "[1/25][543/782] Loss_D: 0.7165 Loss_G: 3.3235\n",
            "[1/25][544/782] Loss_D: 0.8031 Loss_G: 5.9345\n",
            "[1/25][545/782] Loss_D: 0.6798 Loss_G: 2.6916\n",
            "[1/25][546/782] Loss_D: 0.6248 Loss_G: 4.3823\n",
            "[1/25][547/782] Loss_D: 0.4277 Loss_G: 3.1416\n",
            "[1/25][548/782] Loss_D: 0.6308 Loss_G: 5.2412\n",
            "[1/25][549/782] Loss_D: 0.6091 Loss_G: 2.6356\n",
            "[1/25][550/782] Loss_D: 0.7488 Loss_G: 2.9258\n",
            "[1/25][551/782] Loss_D: 0.6480 Loss_G: 5.4786\n",
            "[1/25][552/782] Loss_D: 0.4257 Loss_G: 3.7796\n",
            "[1/25][553/782] Loss_D: 0.3764 Loss_G: 2.8520\n",
            "[1/25][554/782] Loss_D: 0.7991 Loss_G: 6.1267\n",
            "[1/25][555/782] Loss_D: 0.6669 Loss_G: 2.9905\n",
            "[1/25][556/782] Loss_D: 0.4344 Loss_G: 3.8676\n",
            "[1/25][557/782] Loss_D: 0.3222 Loss_G: 4.1106\n",
            "[1/25][558/782] Loss_D: 0.4370 Loss_G: 3.6470\n",
            "[1/25][559/782] Loss_D: 0.2154 Loss_G: 4.1202\n",
            "[1/25][560/782] Loss_D: 0.6883 Loss_G: 1.8980\n",
            "[1/25][561/782] Loss_D: 0.6684 Loss_G: 5.6255\n",
            "[1/25][562/782] Loss_D: 0.8210 Loss_G: 2.0923\n",
            "[1/25][563/782] Loss_D: 0.6422 Loss_G: 5.6882\n",
            "[1/25][564/782] Loss_D: 0.6140 Loss_G: 2.5104\n",
            "[1/25][565/782] Loss_D: 0.5309 Loss_G: 4.6252\n",
            "[1/25][566/782] Loss_D: 0.3567 Loss_G: 3.9010\n",
            "[1/25][567/782] Loss_D: 0.4595 Loss_G: 2.6955\n",
            "[1/25][568/782] Loss_D: 0.5637 Loss_G: 3.1730\n",
            "[1/25][569/782] Loss_D: 0.7157 Loss_G: 2.3934\n",
            "[1/25][570/782] Loss_D: 0.5565 Loss_G: 4.7748\n",
            "[1/25][571/782] Loss_D: 0.5141 Loss_G: 2.7890\n",
            "[1/25][572/782] Loss_D: 0.4960 Loss_G: 4.6206\n",
            "[1/25][573/782] Loss_D: 0.3604 Loss_G: 3.5440\n",
            "[1/25][574/782] Loss_D: 0.4029 Loss_G: 3.7716\n",
            "[1/25][575/782] Loss_D: 0.4263 Loss_G: 3.3055\n",
            "[1/25][576/782] Loss_D: 0.5265 Loss_G: 3.7679\n",
            "[1/25][577/782] Loss_D: 0.4515 Loss_G: 4.2259\n",
            "[1/25][578/782] Loss_D: 0.2394 Loss_G: 3.9493\n",
            "[1/25][579/782] Loss_D: 0.4217 Loss_G: 3.8241\n",
            "[1/25][580/782] Loss_D: 0.2829 Loss_G: 3.6902\n",
            "[1/25][581/782] Loss_D: 0.3133 Loss_G: 3.8660\n",
            "[1/25][582/782] Loss_D: 0.4291 Loss_G: 2.8444\n",
            "[1/25][583/782] Loss_D: 0.5442 Loss_G: 6.3745\n",
            "[1/25][584/782] Loss_D: 0.7834 Loss_G: 2.0134\n",
            "[1/25][585/782] Loss_D: 0.6743 Loss_G: 8.2094\n",
            "[1/25][586/782] Loss_D: 0.3726 Loss_G: 6.3648\n",
            "[1/25][587/782] Loss_D: 0.2457 Loss_G: 2.3843\n",
            "[1/25][588/782] Loss_D: 0.8131 Loss_G: 7.0321\n",
            "[1/25][589/782] Loss_D: 0.2113 Loss_G: 5.8743\n",
            "[1/25][590/782] Loss_D: 0.3302 Loss_G: 1.9050\n",
            "[1/25][591/782] Loss_D: 0.5454 Loss_G: 6.6205\n",
            "[1/25][592/782] Loss_D: 0.9192 Loss_G: 2.4259\n",
            "[1/25][593/782] Loss_D: 0.9432 Loss_G: 7.6989\n",
            "[1/25][594/782] Loss_D: 0.9017 Loss_G: 3.2233\n",
            "[1/25][595/782] Loss_D: 0.8389 Loss_G: 5.2646\n",
            "[1/25][596/782] Loss_D: 0.6410 Loss_G: 2.6551\n",
            "[1/25][597/782] Loss_D: 0.6527 Loss_G: 5.6460\n",
            "[1/25][598/782] Loss_D: 0.3882 Loss_G: 4.7533\n",
            "[1/25][599/782] Loss_D: 0.5468 Loss_G: 2.2278\n",
            "[1/25][600/782] Loss_D: 1.1822 Loss_G: 7.1437\n",
            "[1/25][601/782] Loss_D: 0.9836 Loss_G: 3.4240\n",
            "[1/25][602/782] Loss_D: 0.7157 Loss_G: 4.5543\n",
            "[1/25][603/782] Loss_D: 0.6503 Loss_G: 3.4338\n",
            "[1/25][604/782] Loss_D: 0.5874 Loss_G: 5.3141\n",
            "[1/25][605/782] Loss_D: 0.3149 Loss_G: 4.3916\n",
            "[1/25][606/782] Loss_D: 0.4467 Loss_G: 3.9411\n",
            "[1/25][607/782] Loss_D: 0.5942 Loss_G: 3.3628\n",
            "[1/25][608/782] Loss_D: 0.3750 Loss_G: 4.9420\n",
            "[1/25][609/782] Loss_D: 0.4090 Loss_G: 3.4164\n",
            "[1/25][610/782] Loss_D: 0.8021 Loss_G: 6.5494\n",
            "[1/25][611/782] Loss_D: 0.7704 Loss_G: 3.3550\n",
            "[1/25][612/782] Loss_D: 0.9438 Loss_G: 6.3461\n",
            "[1/25][613/782] Loss_D: 0.7592 Loss_G: 3.4755\n",
            "[1/25][614/782] Loss_D: 1.0499 Loss_G: 5.4959\n",
            "[1/25][615/782] Loss_D: 1.3054 Loss_G: 2.0251\n",
            "[1/25][616/782] Loss_D: 1.8497 Loss_G: 10.8414\n",
            "[1/25][617/782] Loss_D: 4.7654 Loss_G: 2.3583\n",
            "[1/25][618/782] Loss_D: 0.7326 Loss_G: 2.1326\n",
            "[1/25][619/782] Loss_D: 1.1844 Loss_G: 7.4185\n",
            "[1/25][620/782] Loss_D: 0.7752 Loss_G: 5.0994\n",
            "[1/25][621/782] Loss_D: 0.4693 Loss_G: 2.5800\n",
            "[1/25][622/782] Loss_D: 0.9290 Loss_G: 5.5037\n",
            "[1/25][623/782] Loss_D: 0.4586 Loss_G: 4.7961\n",
            "[1/25][624/782] Loss_D: 0.5634 Loss_G: 2.3275\n",
            "[1/25][625/782] Loss_D: 0.6325 Loss_G: 4.6670\n",
            "[1/25][626/782] Loss_D: 0.3631 Loss_G: 4.0162\n",
            "[1/25][627/782] Loss_D: 0.6223 Loss_G: 3.3503\n",
            "[1/25][628/782] Loss_D: 0.5968 Loss_G: 3.0973\n",
            "[1/25][629/782] Loss_D: 0.5817 Loss_G: 5.5814\n",
            "[1/25][630/782] Loss_D: 1.2314 Loss_G: 1.6705\n",
            "[1/25][631/782] Loss_D: 0.8122 Loss_G: 6.0290\n",
            "[1/25][632/782] Loss_D: 0.6773 Loss_G: 2.7573\n",
            "[1/25][633/782] Loss_D: 0.8828 Loss_G: 3.7577\n",
            "[1/25][634/782] Loss_D: 0.4516 Loss_G: 3.1152\n",
            "[1/25][635/782] Loss_D: 0.4934 Loss_G: 3.8762\n",
            "[1/25][636/782] Loss_D: 0.6784 Loss_G: 4.6415\n",
            "[1/25][637/782] Loss_D: 0.6313 Loss_G: 2.6869\n",
            "[1/25][638/782] Loss_D: 0.5764 Loss_G: 3.9286\n",
            "[1/25][639/782] Loss_D: 0.3191 Loss_G: 4.5304\n",
            "[1/25][640/782] Loss_D: 0.3342 Loss_G: 3.2717\n",
            "[1/25][641/782] Loss_D: 0.4426 Loss_G: 3.6225\n",
            "[1/25][642/782] Loss_D: 0.3913 Loss_G: 4.0610\n",
            "[1/25][643/782] Loss_D: 0.4081 Loss_G: 3.6897\n",
            "[1/25][644/782] Loss_D: 0.4506 Loss_G: 3.6227\n",
            "[1/25][645/782] Loss_D: 0.5083 Loss_G: 3.0897\n",
            "[1/25][646/782] Loss_D: 0.4906 Loss_G: 5.2769\n",
            "[1/25][647/782] Loss_D: 0.5499 Loss_G: 2.9019\n",
            "[1/25][648/782] Loss_D: 0.5229 Loss_G: 3.2813\n",
            "[1/25][649/782] Loss_D: 0.4506 Loss_G: 4.7151\n",
            "[1/25][650/782] Loss_D: 0.5442 Loss_G: 2.6542\n",
            "[1/25][651/782] Loss_D: 0.4880 Loss_G: 3.5650\n",
            "[1/25][652/782] Loss_D: 0.2676 Loss_G: 3.7882\n",
            "[1/25][653/782] Loss_D: 0.3200 Loss_G: 3.8512\n",
            "[1/25][654/782] Loss_D: 0.4933 Loss_G: 4.0213\n",
            "[1/25][655/782] Loss_D: 0.8204 Loss_G: 1.5324\n",
            "[1/25][656/782] Loss_D: 1.3246 Loss_G: 7.0083\n",
            "[1/25][657/782] Loss_D: 1.0758 Loss_G: 4.2634\n",
            "[1/25][658/782] Loss_D: 0.3861 Loss_G: 2.1306\n",
            "[1/25][659/782] Loss_D: 0.9029 Loss_G: 6.3728\n",
            "[1/25][660/782] Loss_D: 1.0923 Loss_G: 1.6404\n",
            "[1/25][661/782] Loss_D: 1.0412 Loss_G: 6.2979\n",
            "[1/25][662/782] Loss_D: 0.8148 Loss_G: 3.1590\n",
            "[1/25][663/782] Loss_D: 0.6204 Loss_G: 3.8309\n",
            "[1/25][664/782] Loss_D: 0.4978 Loss_G: 3.8152\n",
            "[1/25][665/782] Loss_D: 0.6333 Loss_G: 2.1676\n",
            "[1/25][666/782] Loss_D: 0.7411 Loss_G: 4.9413\n",
            "[1/25][667/782] Loss_D: 0.4638 Loss_G: 4.1835\n",
            "[1/25][668/782] Loss_D: 0.4661 Loss_G: 2.5634\n",
            "[1/25][669/782] Loss_D: 0.4010 Loss_G: 3.5220\n",
            "[1/25][670/782] Loss_D: 0.7172 Loss_G: 5.4023\n",
            "[1/25][671/782] Loss_D: 0.7266 Loss_G: 2.3535\n",
            "[1/25][672/782] Loss_D: 0.5433 Loss_G: 3.1736\n",
            "[1/25][673/782] Loss_D: 0.7227 Loss_G: 5.4424\n",
            "[1/25][674/782] Loss_D: 0.7690 Loss_G: 2.7433\n",
            "[1/25][675/782] Loss_D: 0.5050 Loss_G: 2.8246\n",
            "[1/25][676/782] Loss_D: 0.6651 Loss_G: 4.9574\n",
            "[1/25][677/782] Loss_D: 0.3964 Loss_G: 3.7344\n",
            "[1/25][678/782] Loss_D: 0.2956 Loss_G: 3.2217\n",
            "[1/25][679/782] Loss_D: 0.4777 Loss_G: 4.2499\n",
            "[1/25][680/782] Loss_D: 0.3120 Loss_G: 3.9706\n",
            "[1/25][681/782] Loss_D: 0.4854 Loss_G: 3.0732\n",
            "[1/25][682/782] Loss_D: 0.5880 Loss_G: 4.2641\n",
            "[1/25][683/782] Loss_D: 0.4814 Loss_G: 3.1118\n",
            "[1/25][684/782] Loss_D: 0.3950 Loss_G: 5.2491\n",
            "[1/25][685/782] Loss_D: 0.9239 Loss_G: 1.7001\n",
            "[1/25][686/782] Loss_D: 1.1163 Loss_G: 7.5267\n",
            "[1/25][687/782] Loss_D: 1.3021 Loss_G: 3.9756\n",
            "[1/25][688/782] Loss_D: 0.2575 Loss_G: 2.7219\n",
            "[1/25][689/782] Loss_D: 0.4834 Loss_G: 4.4751\n",
            "[1/25][690/782] Loss_D: 0.4662 Loss_G: 3.5273\n",
            "[1/25][691/782] Loss_D: 0.4050 Loss_G: 3.7097\n",
            "[1/25][692/782] Loss_D: 0.4942 Loss_G: 3.7430\n",
            "[1/25][693/782] Loss_D: 0.5396 Loss_G: 2.5154\n",
            "[1/25][694/782] Loss_D: 1.0004 Loss_G: 3.1474\n",
            "[1/25][695/782] Loss_D: 0.4653 Loss_G: 2.7274\n",
            "[1/25][696/782] Loss_D: 0.6727 Loss_G: 3.6831\n",
            "[1/25][697/782] Loss_D: 0.3390 Loss_G: 3.4460\n",
            "[1/25][698/782] Loss_D: 0.5767 Loss_G: 2.9476\n",
            "[1/25][699/782] Loss_D: 0.5089 Loss_G: 4.2772\n",
            "[1/25][700/782] Loss_D: 0.3313 Loss_G: 3.5011\n",
            "[1/25][701/782] Loss_D: 0.4007 Loss_G: 2.8905\n",
            "[1/25][702/782] Loss_D: 0.3586 Loss_G: 3.0899\n",
            "[1/25][703/782] Loss_D: 0.3424 Loss_G: 4.2568\n",
            "[1/25][704/782] Loss_D: 0.4949 Loss_G: 2.9424\n",
            "[1/25][705/782] Loss_D: 0.3559 Loss_G: 4.0156\n",
            "[1/25][706/782] Loss_D: 0.4136 Loss_G: 3.4857\n",
            "[1/25][707/782] Loss_D: 0.6094 Loss_G: 4.0949\n",
            "[1/25][708/782] Loss_D: 0.4294 Loss_G: 3.4088\n",
            "[1/25][709/782] Loss_D: 0.7088 Loss_G: 4.2697\n",
            "[1/25][710/782] Loss_D: 0.7865 Loss_G: 2.5213\n",
            "[1/25][711/782] Loss_D: 1.0326 Loss_G: 6.4509\n",
            "[1/25][712/782] Loss_D: 0.5434 Loss_G: 4.5304\n",
            "[1/25][713/782] Loss_D: 0.3399 Loss_G: 3.0407\n",
            "[1/25][714/782] Loss_D: 0.8291 Loss_G: 6.4178\n",
            "[1/25][715/782] Loss_D: 1.0676 Loss_G: 2.2662\n",
            "[1/25][716/782] Loss_D: 1.1179 Loss_G: 6.1180\n",
            "[1/25][717/782] Loss_D: 0.7152 Loss_G: 3.1533\n",
            "[1/25][718/782] Loss_D: 0.9826 Loss_G: 4.6554\n",
            "[1/25][719/782] Loss_D: 0.6930 Loss_G: 2.9040\n",
            "[1/25][720/782] Loss_D: 0.7805 Loss_G: 5.0265\n",
            "[1/25][721/782] Loss_D: 1.0855 Loss_G: 1.5132\n",
            "[1/25][722/782] Loss_D: 0.7710 Loss_G: 5.3170\n",
            "[1/25][723/782] Loss_D: 0.4777 Loss_G: 4.1491\n",
            "[1/25][724/782] Loss_D: 0.7292 Loss_G: 1.8798\n",
            "[1/25][725/782] Loss_D: 1.3545 Loss_G: 6.9423\n",
            "[1/25][726/782] Loss_D: 1.3673 Loss_G: 2.5941\n",
            "[1/25][727/782] Loss_D: 0.7012 Loss_G: 3.4449\n",
            "[1/25][728/782] Loss_D: 0.4998 Loss_G: 3.7292\n",
            "[1/25][729/782] Loss_D: 0.6974 Loss_G: 2.4762\n",
            "[1/25][730/782] Loss_D: 0.8259 Loss_G: 5.5647\n",
            "[1/25][731/782] Loss_D: 0.6075 Loss_G: 2.5770\n",
            "[1/25][732/782] Loss_D: 0.7735 Loss_G: 6.2064\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1qWks7gdLqjYWR9o0QpKV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}